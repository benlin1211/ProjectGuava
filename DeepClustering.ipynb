{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DeepClustering.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JnGlgbZfptL4","colab_type":"text"},"source":["# Deep Clustering\n","[Source code](https://github.com/facebookresearch/deepcluster)\n","\n"]},{"cell_type":"code","metadata":{"id":"WvSUa1Ltplpn","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","mydrive = '/content/drive/'\n","drive.mount(mydrive)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7tLr3w5-OP8Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1591266318278,"user_tz":-480,"elapsed":4146,"user":{"displayName":"仲偉林","photoUrl":"","userId":"16443011482508409666"}},"outputId":"fa6f4d2a-9ca5-492e-a9c8-33c0be9186d5"},"source":["!nvcc --version"],"execution_count":null,"outputs":[{"output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2019 NVIDIA Corporation\n","Built on Sun_Jul_28_19:07:16_PDT_2019\n","Cuda compilation tools, release 10.1, V10.1.243\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"88cuKYwfX1zo","colab_type":"text"},"source":["Change to CUDA 8.0"]},{"cell_type":"code","metadata":{"id":"oVNjwd08Q0lv","colab_type":"code","colab":{}},"source":["# !wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb\n","# !dpkg -i cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb\n","# !apt-get update\n","# !apt-get install cuda=8.0.61-1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CTyjSfp-qKiu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1591266328895,"user_tz":-480,"elapsed":14744,"user":{"displayName":"仲偉林","photoUrl":"","userId":"16443011482508409666"}},"outputId":"a34507b4-34bb-40ba-f775-ae29daa6c6ce"},"source":["!pip install mkl\n","!pip install faiss-gpu==1.6.1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: mkl in /usr/local/lib/python3.6/dist-packages (2019.0)\n","Requirement already satisfied: intel-openmp in /usr/local/lib/python3.6/dist-packages (from mkl) (2020.0.133)\n","Requirement already satisfied: faiss-gpu==1.6.1 in /usr/local/lib/python3.6/dist-packages (1.6.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from faiss-gpu==1.6.1) (1.18.4)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WkyBQ_SvqaAU","colab_type":"text"},"source":["# Import libraries"]},{"cell_type":"code","metadata":{"id":"_cxco7GCqOtg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":318},"executionInfo":{"status":"error","timestamp":1591328177714,"user_tz":-480,"elapsed":19182,"user":{"displayName":"仲偉林","photoUrl":"","userId":"16443011482508409666"}},"outputId":"48d83433-b654-4389-8d1c-bbe8ca99f60f"},"source":["import faiss\n","import torch.backends.cudnn as cudnn"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-5e6cff5ffd81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'faiss'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"qHwWRGASqQlN","colab_type":"code","colab":{}},"source":["import cv2, numpy as np\n","import os, glob\n","import matplotlib.pyplot as plt\n","import time\n","import math"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hudcc9xzjSAm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1591328198261,"user_tz":-480,"elapsed":979,"user":{"displayName":"仲偉林","photoUrl":"","userId":"16443011482508409666"}},"outputId":"bed9678f-46f4-47cc-989d-59e5a6f70de5"},"source":["cwd = os.getcwd()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"SArXxgLEqRg2","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9qRxRr9lQd9E","colab_type":"code","colab":{}},"source":["from torch.utils.data.dataset import Dataset\n","from torch.utils.data import DataLoader\n","from torchvision import transforms, utils\n","import torchvision.datasets as datasets"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8qz3uZ3zrh8G","colab_type":"text"},"source":["# (*)Parameter settings"]},{"cell_type":"code","metadata":{"id":"8giWtlIfrhkJ","colab_type":"code","colab":{}},"source":["#######################################\n","mydrive = '/content/drive/'\n","img_path =  'My Drive/Project/0425guava-classified/'\n","test_path =  'My Drive/Project/0603guava_test/'\n","# arch = 'VGG16'\n","arch = 'alexnet'\n","\n","num_classes = 5\n","batch_size = 32\n","\n","# how many epochs of training between two consecutive reassignments of clusters\n","reassign = 50 # 300\n","# number of data loading workers \n","# num_workers = 0 to solve TypeError: Caught TypeError in DataLoader worker process 0\n","workers = 24\n","\n","start_epoch = 1\n","epochs = 200\n","\n","# criterion_ = 'MSELoss'\n","criterion_ = 'CrossEntropyLoss'\n","\n","# opt = 'SGD'\n","opt = 'Adam'\n","opt_lr = 1e-5    #0.05\n","opt_momentum = 0.9\n","# opt_wd:weight decay (pow)\n","opt_wd = -3       #-5\n","\n","verbose = True\n","\n","# path to checkpoint\n","# resume = os.path.join(mydrive,'My Drive/Project/checkpoint', 'checkpoint.pth.tar')\n","checkpath = 'checkpoint_0602'\n","resume = os.path.join(mydrive,'My Drive/Project/checkpoint_0602', 'checkpoint.pth.tar')\n","\n","mode = 'train'\n","#######################################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4u9SMxFzumdD","colab_type":"text"},"source":["# New Section"]},{"cell_type":"markdown","metadata":{"id":"dQnY9ZTXs9AB","colab_type":"text"},"source":["# Class & Functions"]},{"cell_type":"markdown","metadata":{"id":"CvZaPRVZqpRW","colab_type":"text"},"source":["## Class "]},{"cell_type":"markdown","metadata":{"id":"t9KoCDtKKXWK","colab_type":"text"},"source":["### AverageMeter"]},{"cell_type":"code","metadata":{"id":"dpJH6TdSqTmL","colab_type":"code","colab":{}},"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w78E9UlTKa6c","colab_type":"text"},"source":["### Kmeans (deepcluster)"]},{"cell_type":"code","metadata":{"id":"gE2uO8Z6qxEV","colab_type":"code","colab":{}},"source":["class Kmeans(object):\n","    def __init__(self, k):\n","        self.k = k\n","\n","    def cluster(self, data, verbose=False):\n","        \"\"\"Performs k-means clustering.\n","            Args:\n","                x_data (np.array N * dim): data to cluster\n","        \"\"\"\n","        end = time.time()\n","\n","        # PCA-reducing, whitening and L2-normalization\n","        xb = preprocess_features(data) #\n","\n","        # cluster the data\n","        I, loss = run_kmeans(xb, self.k, verbose)\n","        self.images_lists = [[] for i in range(self.k)]\n","        for i in range(len(data)):\n","            self.images_lists[I[i]].append(i)\n","\n","        if verbose:\n","            print('k-means time: {0:.0f} s'.format(time.time() - end))\n","\n","        return loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gfqm1re8Kd2a","colab_type":"text"},"source":["### UnifLabelSampler"]},{"cell_type":"code","metadata":{"id":"oeYHaiACredZ","colab_type":"code","colab":{}},"source":["from torch.utils.data.sampler import Sampler\n","class UnifLabelSampler(Sampler):\n","    \"\"\"Samples elements uniformely accross pseudolabels.\n","        Args:\n","            N (int): size of returned iterator.\n","            images_lists: dict of key (target), value (list of data with this target)\n","    \"\"\"\n","\n","    def __init__(self, N, images_lists):\n","        self.N = N\n","        self.images_lists = images_lists\n","        self.indexes = self.generate_indexes_epoch()\n","\n","    def generate_indexes_epoch(self):\n","        nmb_non_empty_clusters = 0\n","        for i in range(len(self.images_lists)):\n","            if len(self.images_lists[i]) != 0:\n","                nmb_non_empty_clusters += 1\n","\n","        size_per_pseudolabel = int(self.N / nmb_non_empty_clusters) + 1\n","        res = np.array([])\n","\n","        for i in range(len(self.images_lists)):\n","            # skip empty clusters\n","            if len(self.images_lists[i]) == 0:\n","                continue\n","            indexes = np.random.choice(\n","                self.images_lists[i],\n","                size_per_pseudolabel,\n","                replace=(len(self.images_lists[i]) <= size_per_pseudolabel)\n","            )\n","            res = np.concatenate((res, indexes))\n","\n","        np.random.shuffle(res)\n","        res = list(res.astype('int'))\n","        if len(res) >= self.N:\n","            return res[:self.N]\n","        res += res[: (self.N - len(res))]\n","        return res\n","\n","    def __iter__(self):\n","        return iter(self.indexes)\n","\n","    def __len__(self):\n","        return len(self.indexes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BssWQPYvKh0F","colab_type":"text"},"source":["### ReassignedDataset"]},{"cell_type":"code","metadata":{"id":"lMc2UQncsdxv","colab_type":"code","colab":{}},"source":["import torch.utils.data as data\n","class ReassignedDataset(data.Dataset):\n","    \"\"\"A dataset where the new images labels are given in argument.\n","    Args:\n","        image_indexes (list): list of data indexes\n","        pseudolabels (list): list of labels for each data\n","        dataset (list): list of tuples with paths to images\n","        transform (callable, optional): a function/transform that takes in\n","                                        an PIL image and returns a\n","                                        transformed version\n","    \"\"\"\n","\n","    def __init__(self, image_indexes, pseudolabels, dataset, transform=None):\n","        self.imgs = self.make_dataset(image_indexes, pseudolabels, dataset)\n","        self.transform = transform\n","\n","    def make_dataset(self, image_indexes, pseudolabels, dataset):\n","        label_to_idx = {label: idx for idx, label in enumerate(set(pseudolabels))}\n","        images = []\n","        for j, idx in enumerate(image_indexes):\n","            path = dataset[idx][0]\n","            pseudolabel = label_to_idx[pseudolabels[j]]\n","            images.append((path, pseudolabel))\n","        return images\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        Args:\n","            index (int): index of data\n","        Returns:\n","            tuple: (image, pseudolabel) where pseudolabel is the cluster of index datapoint\n","        \"\"\"\n","        path, pseudolabel = self.imgs[index]\n","        img = pil_loader(path)\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        return img, pseudolabel\n","\n","    def __len__(self):\n","        return len(self.imgs)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"geYuXZjoq33S","colab_type":"text"},"source":["## functions"]},{"cell_type":"markdown","metadata":{"id":"2bt3tx35krI5","colab_type":"text"},"source":["### compute_mean_and_std (not used)\n","Unless you upload new data"]},{"cell_type":"code","metadata":{"id":"kB10Ri5ykqVI","colab_type":"code","colab":{}},"source":["def compute_mean_and_std(loader):\n","    mean = 0.\n","    std = 0.\n","    for images, _ in loader:\n","        batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n","        images = images.view(batch_samples, images.size(1), -1)\n","        mean += images.mean(2).sum(0)\n","        std += images.std(2).sum(0)\n","    mean /= len(loader.dataset)\n","    std /= len(loader.dataset)\n","    return mean, std"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0g_zHnwiKpyb","colab_type":"text"},"source":["### preprocess_features"]},{"cell_type":"code","metadata":{"id":"zJfMRYiFq91E","colab_type":"code","colab":{}},"source":["def preprocess_features(npdata, pca=256):\n","    \"\"\"Preprocess an array of features.\n","    Args:\n","        npdata (np.array N * ndim): features to preprocess\n","        pca (int): dim of output\n","    Returns:\n","        np.array of dim N * pca: data PCA-reduced, whitened and L2-normalized\n","    \"\"\"\n","    _, ndim = npdata.shape\n","    npdata =  npdata.astype('float32')\n","\n","    # Apply PCA-whitening with Faiss\n","    mat = faiss.PCAMatrix (ndim, pca, eigen_power=-0.5)\n","    mat.train(npdata)\n","    assert mat.is_trained\n","    npdata = mat.apply_py(npdata)\n","\n","    # L2 normalization\n","    row_sums = np.linalg.norm(npdata, axis=1)\n","    npdata = npdata / row_sums[:, np.newaxis]\n","\n","    return npdata"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E8ATPmi2l7-H","colab_type":"text"},"source":["### compute_features"]},{"cell_type":"code","metadata":{"id":"yPNXH7G3rXMl","colab_type":"code","colab":{}},"source":["def compute_features(dataloader, model, N, batch_size):\n","    if arch == 'VGG16':\n","        s = 7\n","    elif arch == 'alexnet':\n","        s = 6\n","    print('Compute features')\n","    model.eval()\n","    feature_model = nn.Sequential(\n","        *list(model.features.children()),\n","        nn.AdaptiveAvgPool2d(output_size=(s, s)),\n","        Flatten(),\n","        *list(model.classifier.children())[:-1]\n","    )\n","    feature_model.eval()\n","    # print('f',feature_model)\n","    # discard the label information (catch by _) in the dataloader \n","    with torch.no_grad(): #?\n","        for i, (input_tensor, _) in enumerate(dataloader):\n","            if torch.cuda.is_available():\n","                input_ = torch.autograd.Variable(input_tensor.cuda()) \n","            else:\n","                input_ = torch.autograd.Variable(input_tensor)\n","            # print('input_',input_)\n","            # aux: the feature of a certain data\n","            aux = feature_model(input_).data.cpu().numpy()\n","            # print('aux',aux)\n","            # print(aux.shape)\n","            # initialize\n","            if i == 0:\n","                features = np.zeros((N, aux.shape[1]), dtype='float32')\n","\n","            aux = aux.astype('float32')\n","            if i < len(dataloader) - 1:\n","                features[i * batch_size: (i + 1) * batch_size] = aux\n","            else:\n","                features[i * batch_size:] = aux\n","            # print(aux.shape) # 1,4096\n","\n","    return features"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JAeDY1w6KtDb","colab_type":"text"},"source":["### run_kmeans"]},{"cell_type":"code","metadata":{"id":"bNyQpMN9lojk","colab_type":"code","colab":{}},"source":["def run_kmeans(x, nmb_clusters, verbose=False):\n","    \"\"\"Runs kmeans on 1 GPU.\n","    Args:\n","        x: data\n","        nmb_clusters (int): number of clusters\n","    Returns:\n","        list: ids of data in each cluster\n","    \"\"\"\n","    n_data, d = x.shape\n","\n","    # faiss implementation of k-means\n","    clus = faiss.Clustering(d, nmb_clusters)\n","\n","    # Change faiss seed at each k-means so that the randomly picked\n","    # initialization centroids do not correspond to the same feature ids\n","    # from an epoch to another.\n","    clus.seed = np.random.randint(1234)\n","\n","    clus.niter = 20 # clustering iterations\n","    clus.max_points_per_centroid = 10000000\n","    res = faiss.StandardGpuResources()\n","    flat_config = faiss.GpuIndexFlatConfig()\n","    flat_config.useFloat16 = False\n","    flat_config.device = 0\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache() ##?\n","    index = faiss.GpuIndexFlatL2(res, d, flat_config)\n","\n","    # perform the training\n","    clus.train(x, index)\n","    _, I = index.search(x, 1)\n","    losses = faiss.vector_to_array(clus.obj)\n","\n","    if verbose:\n","        print('k-means loss evolution: {0}'.format(losses))\n","\n","    return [int(n[0]) for n in I], losses[-1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YY17hmZlKr9_","colab_type":"text"},"source":["### cluster_assign"]},{"cell_type":"code","metadata":{"id":"-LQ92lMsq_sC","colab_type":"code","colab":{}},"source":["def cluster_assign(images_lists, dataset, transforms):\n","    \"\"\"Creates a dataset from clustering, with clusters as labels.\n","    Args:\n","        images_lists (list of list): for each cluster, the list of image indexes\n","                                    belonging to this cluster\n","        dataset (list): initial dataset\n","    Returns:\n","        ReassignedDataset(torch.utils.data.Dataset): a dataset with clusters as\n","                                                     labels\n","    \"\"\"\n","    assert images_lists is not None\n","    pseudolabels = []\n","    image_indexes = []\n","    for cluster, images in enumerate(images_lists):\n","        image_indexes.extend(images)\n","        pseudolabels.extend([cluster] * len(images))\n","    \"\"\"\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225])\n","    t = transforms.Compose([transforms.RandomResizedCrop(224),\n","                            transforms.RandomHorizontalFlip(),\n","                            transforms.ToTensor(),\n","                            normalize])\n","    \"\"\"\n","    return ReassignedDataset(image_indexes, pseudolabels, dataset, transforms)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ht9ZLmlEkQDQ","colab_type":"text"},"source":["### pil_loader"]},{"cell_type":"code","metadata":{"id":"gwi1RfSJkPe8","colab_type":"code","colab":{}},"source":["from PIL import Image\n","from PIL import ImageFile\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","\n","def pil_loader(path):\n","    \"\"\"Loads an image.\n","    Args:\n","        path (string): path to image file\n","    Returns:\n","        Image\n","    \"\"\"\n","    with open(path, 'rb') as f:\n","        img = Image.open(f)\n","        return img.convert('RGB')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FRgKS6uiByS_","colab_type":"text"},"source":["## Model"]},{"cell_type":"markdown","metadata":{"id":"t_b3HmhfC0sC","colab_type":"text"},"source":["### VGG16"]},{"cell_type":"code","metadata":{"id":"0eCZHvY2Cz_l","colab_type":"code","colab":{}},"source":["class VGG(nn.Module):\n","\n","    def __init__(self, features, num_classes, sobel):\n","        super(VGG, self).__init__()\n","        self.features = features\n","        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(7, 7))\n","        self.classifier = nn.Sequential(\n","            nn.Linear(512 * 7 * 7, 4096),\n","            nn.ReLU(inplace=True),\n","            # nn.BatchNorm1d(4096), ##\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, 4096), \n","            nn.ReLU(inplace=True)\n","        )\n","        # top layer: the last output layer\n","        self.top_layer = nn.Sequential( ########\n","            nn.Linear(4096, num_classes)  #,\n","            #nn.Softmax()\n","        )\n","        # initialize\n","        self._initialize_weights()\n","        \"\"\"\n","        model.top_layer[:-1].weight.data.normal_(0, 0.01)\n","        model.top_layer[:-1].bias.data.zero_()\n","        \"\"\"\n","        if sobel:\n","            grayscale = nn.Conv2d(3, 1, kernel_size=1, stride=1, padding=0)\n","            grayscale.weight.data.fill_(1.0 / 3.0)\n","            grayscale.bias.data.zero_()\n","            sobel_filter = nn.Conv2d(1, 2, kernel_size=3, stride=1, padding=1)\n","            sobel_filter.weight.data[0,0].copy_(\n","                torch.FloatTensor([[1, 0, -1], [2, 0, -2], [1, 0, -1]])\n","            )\n","            sobel_filter.weight.data[1,0].copy_(\n","                torch.FloatTensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n","            )\n","            sobel_filter.bias.data.zero_()\n","            self.sobel = nn.Sequential(grayscale, sobel_filter)\n","            for p in self.sobel.parameters():\n","                p.requires_grad = False\n","        else:\n","            self.sobel = None\n","\n","    def forward(self, x):\n","        if self.sobel:\n","            x = self.sobel(x)\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","        if self.top_layer:\n","            x = self.top_layer(x)\n","        return x\n","\n","    def _initialize_weights(self):\n","        for y,m in enumerate(self.modules()):\n","            if isinstance(m, nn.Conv2d):\n","                #print(y)\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                for i in range(m.out_channels):\n","                    m.weight.data[i].normal_(0, math.sqrt(2. / n))\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","            elif isinstance(m, nn.Linear):\n","                m.weight.data.normal_(0, 0.01)\n","                m.bias.data.zero_()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"apdl0lsADZuz","colab_type":"text"},"source":["\n","make feature layer"]},{"cell_type":"code","metadata":{"id":"FqFHmLqIB2UZ","colab_type":"code","colab":{}},"source":["def make_layers(input_dim, batch_norm):\n","    layers = []\n","    in_channels = input_dim\n","    cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n","    for v in cfg:\n","        if v == 'M':\n","            layers = layers + [nn.MaxPool2d(kernel_size=2, stride=2)]\n","        else:\n","            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n","            if batch_norm:\n","                layers = layers + [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n","            else:\n","                layers = layers + [conv2d, nn.ReLU(inplace=True)]\n","            in_channels = v\n","    return nn.Sequential(*layers)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7hF9boArB0X7","colab_type":"code","colab":{}},"source":["def vgg16(sobel=False, batch_norm=True, out=num_classes):\n","    dim = 2 + int(not sobel)\n","    model = VGG(make_layers(dim, batch_norm), out, sobel)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pJCmP_D8EhdI","colab_type":"text"},"source":["### alexnet"]},{"cell_type":"code","metadata":{"id":"FAI2WRo4EhAw","colab_type":"code","colab":{}},"source":["class AlexNet(nn.Module):\n","    def __init__(self, features, num_classes, sobel):\n","        super(AlexNet, self).__init__()\n","        self.features = features\n","        self.classifier = nn.Sequential(nn.Dropout(0.5),\n","                            nn.Linear(256 * 6 * 6, 4096),\n","                            nn.ReLU(inplace=True),\n","                            nn.Dropout(0.5),\n","                            nn.Linear(4096, 4096),\n","                            nn.ReLU(inplace=True))\n","\n","        self.top_layer = nn.Linear(4096, num_classes)\n","        self._initialize_weights()\n","\n","        if sobel:\n","            grayscale = nn.Conv2d(3, 1, kernel_size=1, stride=1, padding=0)\n","            grayscale.weight.data.fill_(1.0 / 3.0)\n","            grayscale.bias.data.zero_()\n","            sobel_filter = nn.Conv2d(1, 2, kernel_size=3, stride=1, padding=1)\n","            sobel_filter.weight.data[0, 0].copy_(\n","                torch.FloatTensor([[1, 0, -1], [2, 0, -2], [1, 0, -1]])\n","            )\n","            sobel_filter.weight.data[1, 0].copy_(\n","                torch.FloatTensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n","            )\n","            sobel_filter.bias.data.zero_()\n","            self.sobel = nn.Sequential(grayscale, sobel_filter)\n","            for p in self.sobel.parameters():\n","                p.requires_grad = False\n","        else:\n","            self.sobel = None\n","\n","    def forward(self, x):\n","        if self.sobel:\n","            x = self.sobel(x)\n","        x = self.features(x)\n","        x = x.view(x.size(0), 256 * 6 * 6)\n","        x = self.classifier(x)\n","        if self.top_layer:\n","            x = self.top_layer(x)\n","        return x\n","\n","    def _initialize_weights(self):\n","        for y, m in enumerate(self.modules()):\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                for i in range(m.out_channels):\n","                    m.weight.data[i].normal_(0, math.sqrt(2. / n))\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","            elif isinstance(m, nn.Linear):\n","                m.weight.data.normal_(0, 0.01)\n","                m.bias.data.zero_()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"skPAj93WExuL","colab_type":"code","colab":{}},"source":["def make_layers_features(cfg, input_dim, bn):\n","    layers = []\n","    in_channels = input_dim\n","    for v in cfg:\n","        if v == 'M':\n","            layers = layers + [nn.MaxPool2d(kernel_size=3, stride=2)]\n","        else:\n","            conv2d = nn.Conv2d(in_channels, v[0], kernel_size=v[1], stride=v[2], padding=v[3])\n","            if bn:\n","                layers = layers + [conv2d, nn.BatchNorm2d(v[0]), nn.ReLU(inplace=True)]\n","            else:\n","                layers = layers + [conv2d, nn.ReLU(inplace=True)]\n","            in_channels = v[0]\n","    return nn.Sequential(*layers)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AF-T15j9EzEU","colab_type":"code","colab":{}},"source":["CFG = {\n","    '2012': [(96, 11, 4, 2), 'M', (256, 5, 1, 2), 'M', (384, 3, 1, 1), (384, 3, 1, 1), (256, 3, 1, 1), 'M']\n","}\n","\n","def alexnet(sobel=False, batch_norm=True, out=num_classes):\n","    dim = 2 + int(not sobel)\n","    model = AlexNet(make_layers_features(CFG['2012'], dim, bn=batch_norm), out, sobel)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9dzJZFEhxQlV","colab_type":"text"},"source":["### Flatten\n","To avoid size mismatch of sequential()"]},{"cell_type":"code","metadata":{"id":"IYxDTdljxQJo","colab_type":"code","colab":{}},"source":["class Flatten(nn.Module):\n","    def __init__(self):\n","        super(Flatten, self).__init__()\n","        \n","    def forward(self, x):\n","        return x.view(x.size(0), -1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PijwAPVPrDrZ","colab_type":"text"},"source":["## *Train function"]},{"cell_type":"code","metadata":{"id":"xbGpE6NqrKpO","colab_type":"code","colab":{}},"source":["def train(loader, model, crit, opt, epoch, opt_lr, opt_wd, verbose = True):\n","    \n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    data_time = AverageMeter()\n","    forward_time = AverageMeter()\n","    backward_time = AverageMeter()\n","\n","    # switch to train mode\n","    model.train()\n","\n","    # print(model)\n","    # create an optimizer for the last fc layer\n","    optimizer_tl = torch.optim.SGD(\n","        model.top_layer.parameters(),\n","        lr=opt_lr,\n","        weight_decay=10**opt_wd,\n","    )\n","\n","    end = time.time()\n","\n","    print('len(loader): ', len(loader))\n","    for i, (input_tensor, target) in enumerate(loader):\n","        data_time.update(time.time() - end)\n","\n","        if torch.cuda.is_available():\n","            target = target.cuda(async=True)\n","        if torch.cuda.is_available():\n","            input_var = torch.autograd.Variable(input_tensor.cuda())\n","        else:\n","            input_var = torch.autograd.Variable(input_tensor)\n","        target_var = torch.autograd.Variable(target)\n","        \n","        output = model(input_var)\n","        # output: predict result\n","        # target_var: (pesudo) ground truth\n","        # assert 0 not in output, 'Gotcha!'\n","\n","        loss = crit(output, target_var)\n","        \n","        # print(output)\n","        # record loss\n","        losses.update(loss.data, input_tensor.size(0))\n","\n","        # compute gradient and do SGD step(\n","        with  torch.autograd.detect_anomaly():\n","            \n","            opt.zero_grad()\n","            optimizer_tl.zero_grad()\n","            \n","            loss.backward()\n","            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm, norm_type=2)\n","            torch.nn.utils.clip_grad_value_(model.parameters(), 1)\n","            opt.step()\n","            optimizer_tl.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if verbose and (i % 200) == 0:\n","            \n","            print ('out:')\n","            print(output)\n","            print(output.shape)\n","            print ('cluster_var:')\n","            print(target_var)\n","            print(target_var.shape)\n","            \n","            print('Progress report:\\t'\n","                  'Epoch: [{0}][{1}/{2}]\\t'\n","                  'Time: {batch_time.val:.3f} (avg: {batch_time.avg:.3f})\\t'\n","                  'Data: {data_time.val:.3f} (avg: {data_time.avg:.3f})\\t'\n","                  'Loss: {loss.val:.4f} (avg: {loss.avg:.4f})'\n","                  .format(epoch, i, len(loader), batch_time=batch_time,\n","                          data_time=data_time, loss=losses))\n","        # ???\n","    return losses.avg\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VnR85PKLtIbh","colab_type":"text"},"source":["# Main "]},{"cell_type":"markdown","metadata":{"id":"36Z19UGFuDf2","colab_type":"text"},"source":["## Model, optimizer, loss function, and cluster\n","\n","cudnn.benchmark = True [link](https://zhuanlan.zhihu.com/p/73711222)"]},{"cell_type":"code","metadata":{"id":"j-Ecqx2Fty53","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":595},"executionInfo":{"status":"ok","timestamp":1591266330178,"user_tz":-480,"elapsed":15860,"user":{"displayName":"仲偉林","photoUrl":"","userId":"16443011482508409666"}},"outputId":"c1542f26-ecc9-400f-ca53-b688b9c0f5f0"},"source":["import torchvision.models as models\n","\n"," # CNN\n","if arch == 'VGG16':\n","    model = vgg16(sobel=False, batch_norm=True, out=num_classes)\n","elif arch == 'alexnet':\n","    model = alexnet(sobel=False, batch_norm=True, out=num_classes)\n","\n","if torch.cuda.is_available():\n","    model = model.cuda()\n","cudnn.benchmark = True \n","\n","# create optimizer\n","# If you see NaN's in loss try gradient clipping and data normalisation.\n","# Normalising data is a must (i.e normalize input data such that mean = 0 and variance =1)\n","assert opt is not None, 'Please select SGD or Adam'\n","if opt == 'SGD':\n","    optimizer = torch.optim.SGD(\n","        filter(lambda x: x.requires_grad, model.parameters()),\n","        lr=opt_lr,\n","        momentum=opt_momentum,\n","        weight_decay=10**opt_wd\n","    )\n","elif opt == 'Adam':\n","    optimizer = torch.optim.Adam(\n","        filter(lambda x: x.requires_grad, model.parameters()),\n","        lr=opt_lr, \n","        betas=(opt_momentum, 0.999),\n","        weight_decay=10**opt_wd\n","    )\n","# define loss function\n","if torch.cuda.is_available():\n","    if criterion_ == 'CrossEntropyLoss':\n","        criterion = nn.CrossEntropyLoss().cuda()\n","    elif criterion_ == 'MSELoss':\n","        criterion = nn.MSELoss().cuda()\n","else:\n","    if criterion_ == 'CrossEntropyLoss':\n","        criterion = nn.CrossEntropyLoss()\n","    elif criterion_ == 'MSELoss':\n","        criterion = nn.MSELoss()\n","\n","# specify clustering algorithm\n","deepcluster = Kmeans(num_classes)\n","print(model)\n","print(opt)\n","print('================================================')\n","feature_model = nn.Sequential(\n","    *list(model.features.children()),\n","    nn.AdaptiveAvgPool2d(output_size=(7, 7)),\n","    Flatten(),\n","    *list(model.classifier.children())[:-1]\n","    )\n","# print(feature_model)\n","print('================================================')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["AlexNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): ReLU(inplace=True)\n","    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): ReLU(inplace=True)\n","    (11): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (12): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace=True)\n","    (17): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=9216, out_features=4096, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=4096, out_features=4096, bias=True)\n","    (5): ReLU(inplace=True)\n","  )\n","  (top_layer): Linear(in_features=4096, out_features=5, bias=True)\n",")\n","Adam\n","================================================\n","================================================\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hWWBRMnro66C","colab_type":"text"},"source":["## Resume from a checkpoint\n","Load last start_epoch, model_state, and resume path. "]},{"cell_type":"code","metadata":{"id":"aGB4Gx2fo3m1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1591266331395,"user_tz":-480,"elapsed":17066,"user":{"displayName":"仲偉林","photoUrl":"","userId":"16443011482508409666"}},"outputId":"149b06b1-a477-464a-d559-1d80c300cd24"},"source":["# remove last layer to load weight properly\n","# because we don't have parameters of last layer    \n","\n","# model.classifier = nn.Sequential(*list(model.classifier.children())[:-1])\n","# print(model)\n","\n","if resume:\n","    if os.path.isfile(resume):\n","        print(\"=> loading checkpoint '{}'\".format(resume))\n","        layer = model.top_layer\n","        model.top_layer = None\n","\n","        checkpoint = torch.load(resume)\n","        start_epoch = checkpoint['epoch']\n","        # remove top_layer parameters from checkpoint\n","        for key in list(checkpoint['state_dict']):\n","            if 'top_layer' in key:\n","                del checkpoint['state_dict'][key]\n","        model.load_state_dict(checkpoint['state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer'])\n","        print(\"=> loaded checkpoint '{}' (epoch {})\"\n","              .format(resume, checkpoint['epoch']))\n","         \n","        model.top_layer = layer\n","        # top layer unloaded ?\n","    else:\n","        print(\"=> no checkpoint found at '{}'\".format(resume))\n","else:\n","    print(\"=> Let's go. \")\n","# add ReLU back\n","# mlp = list(model.classifier.children())\n","# add another ReLU\n","# mlp.append(nn.ReLU(inplace=True).cuda())\n","# model.classifier = nn.Sequential(*mlp)\n","# print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["=> loading checkpoint '/content/drive/My Drive/Project/checkpoint_0602/checkpoint.pth.tar'\n","=> loaded checkpoint '/content/drive/My Drive/Project/checkpoint_0602/checkpoint.pth.tar' (epoch 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"of9yZ3Uuo4n6","colab_type":"code","colab":{}},"source":["# creating checkpoint repo file\n","\n","exp_check = os.path.join(mydrive,'My Drive/Project', checkpath)\n","if not os.path.isdir(exp_check):\n","    os.makedirs(exp_check)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gmYZTJCaPtuu","colab_type":"text"},"source":["## preprocessing of data & dataloader"]},{"cell_type":"code","metadata":{"id":"iS4iRbS7tPny","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1591266331398,"user_tz":-480,"elapsed":17053,"user":{"displayName":"仲偉林","photoUrl":"","userId":"16443011482508409666"}},"outputId":"4a11524e-211d-4d2b-d3fe-39ddeb26b68c"},"source":["\"\"\"\n","\n","tra = transforms.Compose([\n","                transforms.Resize((224, 224),interpolation=3),\n","                transforms.ToTensor() # Turn to tensor to do some calculation\n","            ])\n","\n","guava_dataset = datasets.ImageFolder(os.path.join(mydrive,img_path),\n","                                     transform=tra)\n","print('len(guava_dataset) = ',len(guava_dataset))\n","guava_dataloader = DataLoader(guava_dataset, batch_size ,shuffle=True)\n","print('len(guava_dataloader) = ',len(guava_dataloader))\n","\n","(mean,std) = compute_mean_and_std(guava_dataloader)\n","\n","\"\"\"\n","\n","mean = [0.4492, 0.4598, 0.2279]\n","std = [0.2745, 0.2809, 0.1241]\n","\n","normalize = transforms.Normalize( mean = mean, std = std )\n","print('mean = {0} \\n, std = {1} \\n' .format(mean, std))\n","# ============================================================================\n","tra = transforms.Compose([\n","                transforms.Resize((224, 224),interpolation=3),\n","                transforms.ToTensor(),\n","                normalize\n","            ])\n","guava_dataset = datasets.ImageFolder(os.path.join(mydrive,img_path),\n","                                     transform=tra)\n","guava_dataloader =  DataLoader(guava_dataset, batch_size ,shuffle=True)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mean = [0.4492, 0.4598, 0.2279] \n",", std = [0.2745, 0.2809, 0.1241] \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wMeJCdHguqZj","colab_type":"text"},"source":["## *Main loop"]},{"cell_type":"code","metadata":{"id":"aHwYEjFDuJNE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f47a7624-dafa-4b88-f1d3-6cb331502789"},"source":["if mode == 'train':\n","    print('train')\n","    for epoch in range(start_epoch, epochs):\n","\n","        t0 = time.time()\n","        \"\"\"\n","        # remove head, the last output layer\n","        model.top_layer = None\n","        # remove ReLU \n","        model.classifier = nn.Sequential(*list(model.classifier.children())[:-1])\n","        \"\"\"\n","        # print('model',model)\n","        # Step1: get the features for the whole dataset\n","        print('Step1: get the features for the whole dataset')\n","        # print('guava_dataset:',guava_dataset) \n","        features = compute_features(guava_dataloader, model, len(guava_dataset), batch_size)\n","        print('features:',features)\n","\n","        # Step2: cluster the features\n","        print('Step2: cluster the features')\n","        clustering_loss = deepcluster.cluster(features, verbose)\n","\n","        # Step3: assign pseudo-labels\n","        print('Step3: assign pseudo-labels')\n","        train_dataset = cluster_assign(deepcluster.images_lists, guava_dataset.imgs, tra) \n","\n","        # Step4: uniformly sample for each target\n","        print('Step4: uniformly sample for each target')\n","        sampler = UnifLabelSampler(int(reassign * len(train_dataset)), deepcluster.images_lists)\n","        train_dataloader = torch.utils.data.DataLoader(\n","            train_dataset,\n","            batch_size=batch_size,\n","            num_workers=workers,\n","            sampler=sampler,\n","            pin_memory=True,\n","        )\n","        # Step5: set last fully connected layer\n","        print('Step5: set last fully connected layer')\n","\n","        \"\"\"\n","        mlp = list(model.classifier.children())\n","        \n","        # add another ReLU (don't set inplace)\n","        \n","        # add another ReLU\n","        # Use softmax instead\n","        mlp.append(nn.ReLU(inplace = False).cuda())\n","        # print(*mlp) \n","        model.classifier = nn.Sequential(*mlp)\n","    \n","        # initialize top layer\n","        \"\"\"\n","        \n","        # print(model)\n","        # Step6: train network with clusters as pseudo-labels\n","        print('Step6: train network with clusters as pseudo-labels')\n","\n","        t1 = time.time()\n","        loss = train(train_dataloader, model, criterion, optimizer, epoch,  \\\n","                    opt_lr, opt_wd, verbose)\n","        t2 = time.time()\n","\n","        # Step7: save running checkpoint\n","        print('Step7: save running checkpoint')\n","        torch.save({'epoch': epoch + 1,\n","                    'arch': arch,\n","                    'opt': opt,\n","                    'state_dict': model.state_dict(),\n","                    'optimizer' : optimizer.state_dict()},\n","                    os.path.join(mydrive,'My Drive/Project',checkpath, 'checkpoint.pth.tar'))\n","\n","        if verbose:\n","            print('############# Epoch [{0}] report ############# \\n' \\\n","                'Time 1: {1:.3f} s\\n' \\\n","                'Time 1: {1:.3f} s\\n' \\\n","                'Clustering loss: {2:.3f} \\n' \\\n","                'ConvNet loss: {3:.3f} \\n' \\\n","                '############ End epoch [{0}] report ########## \\n' \\\n","                .format(epoch, t1 - t0, t2 - t1, clustering_loss, loss))\n","        "],"execution_count":null,"outputs":[{"output_type":"stream","text":["train\n","Step1: get the features for the whole dataset\n","Compute features\n","features: [[ 0.37955683  0.8571422  -0.52292067 ...  0.00842863  0.5645535\n","  -0.26267487]\n"," [ 0.141464    0.72423005 -0.7083073  ...  0.4722571   0.55242527\n","  -0.0551686 ]\n"," [ 0.239245    0.76025784 -0.62738    ...  0.3822163   0.9930638\n","  -0.1618071 ]\n"," ...\n"," [ 0.06620793  0.92664254 -0.77333224 ...  0.6250489   0.62830865\n","  -0.46402222]\n"," [-0.1360004   0.97198755 -1.0783222  ...  0.37755868  0.63277435\n","  -0.25918686]\n"," [ 0.13586189  0.88176936 -0.4949621  ...  0.36110592  0.7637077\n","  -0.29607683]]\n","Step2: cluster the features\n","k-means loss evolution: [1343.1305   713.9787   713.31525  713.05066  712.8518   712.68164\n","  712.5434   712.48047  712.4475   712.4301   712.3946   712.3782\n","  712.3782   712.3782   712.3782   712.3782   712.3782   712.3782\n","  712.3782   712.3782 ]\n","k-means time: 1 s\n","Step3: assign pseudo-labels\n","Step4: uniformly sample for each target\n","Step5: set last fully connected layer\n","Step6: train network with clusters as pseudo-labels\n","len(loader):  1127\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/autograd/anomaly_mode.py:70: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n","  warnings.warn('Anomaly Detection has been enabled. '\n"],"name":"stderr"},{"output_type":"stream","text":["out:\n","tensor([[ 0.6945, -1.0512, -1.1539, -0.9234,  0.2700],\n","        [ 0.4432, -1.0883, -0.3324, -0.5553, -0.4964],\n","        [ 0.4599, -0.7193, -0.9094, -0.3776, -0.1272],\n","        [-0.1314, -0.8690, -0.5977,  0.0174, -0.2885],\n","        [-0.4507, -0.9543,  0.0279, -0.2395, -0.1834],\n","        [-0.1761, -0.5596, -0.7425, -0.3912, -0.3070],\n","        [-0.9023, -0.2728, -0.6338, -0.8357, -0.3903],\n","        [-0.0467, -0.2001, -0.6481, -0.5892,  0.1255],\n","        [-0.4088, -1.1142, -0.1030, -0.7698, -0.0504],\n","        [-0.6962, -1.1641, -0.2350, -0.6592,  0.0084],\n","        [ 0.3256, -0.5138, -0.0410, -0.7859,  0.0079],\n","        [-0.1299, -0.7511, -0.0517, -1.0091, -1.1775],\n","        [ 0.3671, -0.3899, -0.3729, -0.6866, -0.0690],\n","        [-0.5482, -1.3033, -0.3404, -0.4224, -0.1657],\n","        [ 0.0975, -0.4292, -0.4444, -1.0720,  0.0432],\n","        [-0.4218, -0.6880, -0.5751, -0.6527,  0.0739],\n","        [-0.1426, -0.4530, -0.4657, -0.8654, -0.3972],\n","        [ 0.4443, -0.2951, -0.5458, -0.7074, -0.1687],\n","        [ 0.0326, -1.2334, -0.5204, -0.5438, -0.5487],\n","        [-0.2794, -0.5548, -0.8330, -0.6834, -0.2145],\n","        [-0.2073, -0.6256, -0.2139, -1.0625,  0.0993],\n","        [ 0.3897, -0.6312, -0.2940, -0.3718, -0.2495],\n","        [-0.0236, -1.0588, -0.8801, -0.7569,  0.0434],\n","        [ 0.0969, -0.8479, -0.4846, -0.2726, -0.6692],\n","        [ 0.2258, -0.5805, -0.3149, -0.7065, -0.3708],\n","        [ 0.3416, -0.3308, -0.8948, -0.1669,  0.1021],\n","        [ 0.0345, -0.7399, -0.1524, -0.2048, -0.1964],\n","        [-0.1348, -0.7787, -0.0914, -1.2176,  0.2762],\n","        [ 0.2082, -0.9447, -0.6848, -0.4317, -0.0094],\n","        [ 0.4966, -0.4979, -0.4330, -0.4102, -0.3835],\n","        [ 0.2985, -1.0779, -0.6596, -0.2682, -0.2259],\n","        [ 0.0325, -0.8042, -0.5544, -0.6709, -0.2238]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([4, 0, 4, 2, 3, 1, 1, 1, 4, 4, 2, 2, 4, 2, 0, 1, 4, 3, 3, 4, 4, 3, 0, 3,\n","        3, 1, 3, 3, 4, 4, 3, 1], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [2][0/1127]\tTime: 10.450 (avg: 10.450)\tData: 9.983 (avg: 9.983)\tLoss: 1.5636 (avg: 1.5636)\n","out:\n","tensor([[ 0.0047, -0.0038, -0.0107,  0.0003,  0.0091],\n","        [ 0.0058, -0.0047, -0.0131,  0.0004,  0.0111],\n","        [ 0.0060, -0.0048, -0.0134,  0.0004,  0.0113],\n","        [ 0.0050, -0.0040, -0.0110,  0.0003,  0.0093],\n","        [ 0.0048, -0.0038, -0.0108,  0.0002,  0.0092],\n","        [ 0.0052, -0.0043, -0.0117,  0.0005,  0.0098],\n","        [ 0.0063, -0.0051, -0.0142,  0.0005,  0.0121],\n","        [ 0.0065, -0.0053, -0.0146,  0.0003,  0.0126],\n","        [ 0.0058, -0.0048, -0.0131,  0.0004,  0.0113],\n","        [ 0.0057, -0.0046, -0.0129,  0.0004,  0.0109],\n","        [ 0.0060, -0.0047, -0.0131,  0.0003,  0.0110],\n","        [ 0.0047, -0.0038, -0.0108,  0.0002,  0.0092],\n","        [ 0.0055, -0.0045, -0.0126,  0.0003,  0.0109],\n","        [ 0.0061, -0.0050, -0.0140,  0.0003,  0.0121],\n","        [ 0.0060, -0.0051, -0.0138,  0.0005,  0.0118],\n","        [ 0.0058, -0.0048, -0.0131,  0.0006,  0.0111],\n","        [ 0.0057, -0.0048, -0.0129,  0.0003,  0.0111],\n","        [ 0.0062, -0.0050, -0.0137,  0.0006,  0.0114],\n","        [ 0.0063, -0.0049, -0.0135,  0.0002,  0.0115],\n","        [ 0.0082, -0.0064, -0.0185,  0.0007,  0.0154],\n","        [ 0.0056, -0.0046, -0.0126,  0.0002,  0.0109],\n","        [ 0.0059, -0.0047, -0.0134,  0.0004,  0.0113],\n","        [ 0.0061, -0.0050, -0.0131,  0.0004,  0.0112],\n","        [ 0.0053, -0.0044, -0.0121,  0.0003,  0.0104],\n","        [ 0.0060, -0.0049, -0.0134,  0.0005,  0.0114],\n","        [ 0.0072, -0.0062, -0.0163,  0.0006,  0.0141],\n","        [ 0.0047, -0.0041, -0.0112,  0.0005,  0.0096],\n","        [ 0.0043, -0.0034, -0.0099,  0.0004,  0.0083],\n","        [ 0.0054, -0.0046, -0.0121,  0.0003,  0.0105],\n","        [ 0.0062, -0.0049, -0.0138,  0.0004,  0.0117],\n","        [ 0.0057, -0.0045, -0.0125,  0.0004,  0.0105],\n","        [ 0.0065, -0.0053, -0.0151,  0.0004,  0.0129]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([1, 3, 0, 4, 1, 1, 1, 0, 4, 0, 1, 0, 0, 3, 4, 4, 1, 3, 3, 0, 3, 0, 0, 3,\n","        0, 4, 3, 4, 2, 1, 3, 3], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [2][200/1127]\tTime: 0.360 (avg: 0.413)\tData: 0.000 (avg: 0.051)\tLoss: 1.6069 (avg: 1.6083)\n","out:\n","tensor([[-0.0043, -0.0024, -0.0147, -0.0055,  0.0259],\n","        [-0.0027, -0.0015, -0.0095, -0.0036,  0.0166],\n","        [-0.0048, -0.0027, -0.0163, -0.0065,  0.0291],\n","        [-0.0033, -0.0018, -0.0113, -0.0044,  0.0200],\n","        [-0.0033, -0.0020, -0.0118, -0.0046,  0.0208],\n","        [-0.0033, -0.0018, -0.0112, -0.0043,  0.0198],\n","        [-0.0053, -0.0029, -0.0177, -0.0068,  0.0315],\n","        [-0.0061, -0.0035, -0.0206, -0.0081,  0.0369],\n","        [-0.0039, -0.0019, -0.0125, -0.0052,  0.0225],\n","        [-0.0035, -0.0020, -0.0122, -0.0047,  0.0214],\n","        [-0.0036, -0.0022, -0.0127, -0.0049,  0.0225],\n","        [-0.0036, -0.0018, -0.0120, -0.0044,  0.0210],\n","        [-0.0043, -0.0021, -0.0137, -0.0053,  0.0243],\n","        [-0.0035, -0.0018, -0.0121, -0.0047,  0.0212],\n","        [-0.0036, -0.0019, -0.0118, -0.0046,  0.0210],\n","        [-0.0043, -0.0027, -0.0140, -0.0054,  0.0253],\n","        [-0.0036, -0.0021, -0.0126, -0.0048,  0.0221],\n","        [-0.0048, -0.0028, -0.0164, -0.0065,  0.0292],\n","        [-0.0042, -0.0027, -0.0145, -0.0054,  0.0258],\n","        [-0.0038, -0.0020, -0.0130, -0.0051,  0.0230],\n","        [-0.0034, -0.0018, -0.0115, -0.0046,  0.0204],\n","        [-0.0036, -0.0019, -0.0123, -0.0049,  0.0219],\n","        [-0.0034, -0.0020, -0.0113, -0.0043,  0.0200],\n","        [-0.0039, -0.0021, -0.0129, -0.0049,  0.0228],\n","        [-0.0041, -0.0021, -0.0131, -0.0052,  0.0234],\n","        [-0.0048, -0.0028, -0.0158, -0.0062,  0.0284],\n","        [-0.0036, -0.0019, -0.0123, -0.0047,  0.0216],\n","        [-0.0043, -0.0022, -0.0150, -0.0056,  0.0261],\n","        [-0.0042, -0.0021, -0.0143, -0.0057,  0.0253],\n","        [-0.0040, -0.0023, -0.0140, -0.0056,  0.0248],\n","        [-0.0032, -0.0020, -0.0112, -0.0042,  0.0198],\n","        [-0.0033, -0.0018, -0.0111, -0.0044,  0.0198]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([2, 4, 4, 0, 4, 4, 4, 4, 0, 0, 2, 0, 0, 0, 1, 2, 3, 3, 1, 0, 4, 1, 2, 1,\n","        3, 4, 4, 0, 4, 4, 0, 4], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [2][400/1127]\tTime: 0.308 (avg: 0.380)\tData: 0.000 (avg: 0.026)\tLoss: 1.6036 (avg: 1.6080)\n","out:\n","tensor([[ 0.0114, -0.0147, -0.0337,  0.0171,  0.0198],\n","        [ 0.0133, -0.0169, -0.0388,  0.0197,  0.0225],\n","        [ 0.0099, -0.0125, -0.0285,  0.0144,  0.0167],\n","        [ 0.0082, -0.0106, -0.0245,  0.0125,  0.0143],\n","        [ 0.0099, -0.0125, -0.0291,  0.0145,  0.0171],\n","        [ 0.0088, -0.0114, -0.0262,  0.0133,  0.0154],\n","        [ 0.0117, -0.0149, -0.0343,  0.0172,  0.0201],\n","        [ 0.0100, -0.0129, -0.0291,  0.0147,  0.0171],\n","        [ 0.0129, -0.0166, -0.0380,  0.0192,  0.0223],\n","        [ 0.0117, -0.0149, -0.0342,  0.0171,  0.0201],\n","        [ 0.0099, -0.0130, -0.0293,  0.0149,  0.0172],\n","        [ 0.0111, -0.0141, -0.0327,  0.0163,  0.0192],\n","        [ 0.0111, -0.0144, -0.0330,  0.0165,  0.0196],\n","        [ 0.0118, -0.0152, -0.0351,  0.0177,  0.0206],\n","        [ 0.0098, -0.0124, -0.0287,  0.0142,  0.0169],\n","        [ 0.0097, -0.0123, -0.0288,  0.0142,  0.0170],\n","        [ 0.0108, -0.0140, -0.0319,  0.0162,  0.0187],\n","        [ 0.0108, -0.0135, -0.0311,  0.0157,  0.0180],\n","        [ 0.0100, -0.0127, -0.0292,  0.0148,  0.0169],\n","        [ 0.0113, -0.0145, -0.0335,  0.0170,  0.0194],\n","        [ 0.0105, -0.0135, -0.0310,  0.0155,  0.0184],\n","        [ 0.0092, -0.0117, -0.0270,  0.0133,  0.0159],\n","        [ 0.0101, -0.0132, -0.0302,  0.0152,  0.0178],\n","        [ 0.0135, -0.0171, -0.0398,  0.0197,  0.0234],\n","        [ 0.0094, -0.0119, -0.0272,  0.0137,  0.0159],\n","        [ 0.0089, -0.0117, -0.0265,  0.0133,  0.0157],\n","        [ 0.0099, -0.0126, -0.0288,  0.0144,  0.0170],\n","        [ 0.0102, -0.0129, -0.0296,  0.0147,  0.0174],\n","        [ 0.0088, -0.0111, -0.0257,  0.0129,  0.0150],\n","        [ 0.0083, -0.0107, -0.0245,  0.0123,  0.0144],\n","        [ 0.0115, -0.0145, -0.0332,  0.0163,  0.0196],\n","        [ 0.0098, -0.0123, -0.0286,  0.0143,  0.0168]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([4, 3, 0, 4, 3, 1, 0, 4, 0, 4, 2, 2, 0, 2, 0, 4, 1, 4, 1, 0, 1, 0, 1, 3,\n","        1, 4, 4, 4, 3, 2, 3, 0], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [2][600/1127]\tTime: 0.314 (avg: 0.370)\tData: 0.000 (avg: 0.018)\tLoss: 1.6056 (avg: 1.6077)\n","out:\n","tensor([[ 0.0131,  0.0082, -0.0526, -0.0180,  0.0480],\n","        [ 0.0163,  0.0097, -0.0647, -0.0219,  0.0589],\n","        [ 0.0157,  0.0096, -0.0624, -0.0216,  0.0572],\n","        [ 0.0116,  0.0071, -0.0460, -0.0156,  0.0417],\n","        [ 0.0119,  0.0073, -0.0476, -0.0164,  0.0436],\n","        [ 0.0141,  0.0086, -0.0563, -0.0191,  0.0512],\n","        [ 0.0144,  0.0087, -0.0568, -0.0196,  0.0519],\n","        [ 0.0149,  0.0093, -0.0599, -0.0201,  0.0543],\n","        [ 0.0140,  0.0089, -0.0570, -0.0192,  0.0519],\n","        [ 0.0127,  0.0077, -0.0510, -0.0173,  0.0466],\n","        [ 0.0136,  0.0085, -0.0550, -0.0187,  0.0502],\n","        [ 0.0175,  0.0106, -0.0694, -0.0235,  0.0631],\n","        [ 0.0113,  0.0069, -0.0450, -0.0154,  0.0411],\n","        [ 0.0115,  0.0072, -0.0464, -0.0157,  0.0422],\n","        [ 0.0160,  0.0097, -0.0638, -0.0218,  0.0584],\n","        [ 0.0138,  0.0086, -0.0558, -0.0190,  0.0510],\n","        [ 0.0135,  0.0085, -0.0549, -0.0185,  0.0500],\n","        [ 0.0149,  0.0095, -0.0615, -0.0204,  0.0559],\n","        [ 0.0167,  0.0103, -0.0668, -0.0228,  0.0610],\n","        [ 0.0142,  0.0088, -0.0573, -0.0195,  0.0523],\n","        [ 0.0141,  0.0085, -0.0556, -0.0190,  0.0506],\n","        [ 0.0157,  0.0097, -0.0632, -0.0215,  0.0577],\n","        [ 0.0128,  0.0079, -0.0508, -0.0173,  0.0462],\n","        [ 0.0187,  0.0112, -0.0738, -0.0253,  0.0674],\n","        [ 0.0152,  0.0094, -0.0610, -0.0207,  0.0555],\n","        [ 0.0153,  0.0095, -0.0614, -0.0210,  0.0561],\n","        [ 0.0137,  0.0085, -0.0546, -0.0186,  0.0496],\n","        [ 0.0101,  0.0064, -0.0411, -0.0139,  0.0376],\n","        [ 0.0129,  0.0077, -0.0514, -0.0174,  0.0469],\n","        [ 0.0134,  0.0084, -0.0545, -0.0184,  0.0498],\n","        [ 0.0136,  0.0087, -0.0555, -0.0189,  0.0507],\n","        [ 0.0135,  0.0084, -0.0542, -0.0187,  0.0496]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([1, 3, 4, 2, 0, 1, 0, 3, 3, 0, 3, 0, 4, 1, 2, 1, 1, 0, 1, 0, 4, 4, 0, 4,\n","        0, 1, 1, 0, 2, 0, 4, 3], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [2][800/1127]\tTime: 0.315 (avg: 0.364)\tData: 0.000 (avg: 0.013)\tLoss: 1.6013 (avg: 1.6075)\n","out:\n","tensor([[-0.1391, -0.0485, -0.0942,  0.0753,  0.2054],\n","        [-0.1264, -0.0442, -0.0851,  0.0685,  0.1862],\n","        [-0.1442, -0.0506, -0.0979,  0.0781,  0.2133],\n","        [-0.1507, -0.0530, -0.1023,  0.0820,  0.2229],\n","        [-0.1379, -0.0485, -0.0933,  0.0747,  0.2036],\n","        [-0.1909, -0.0665, -0.1288,  0.1032,  0.2817],\n","        [-0.1537, -0.0546, -0.1042,  0.0833,  0.2277],\n","        [-0.1388, -0.0485, -0.0937,  0.0751,  0.2048],\n","        [-0.1363, -0.0479, -0.0919,  0.0738,  0.2010],\n","        [-0.1564, -0.0553, -0.1061,  0.0846,  0.2317],\n","        [-0.1109, -0.0388, -0.0749,  0.0604,  0.1636],\n","        [-0.1500, -0.0524, -0.1019,  0.0816,  0.2215],\n","        [-0.1338, -0.0473, -0.0909,  0.0729,  0.1977],\n","        [-0.1756, -0.0615, -0.1194,  0.0950,  0.2598],\n","        [-0.1468, -0.0513, -0.0991,  0.0795,  0.2165],\n","        [-0.1279, -0.0444, -0.0858,  0.0692,  0.1880],\n","        [-0.0966, -0.0337, -0.0648,  0.0525,  0.1422],\n","        [-0.1450, -0.0507, -0.0984,  0.0787,  0.2140],\n","        [-0.1198, -0.0421, -0.0814,  0.0653,  0.1769],\n","        [-0.1168, -0.0410, -0.0788,  0.0631,  0.1726],\n","        [-0.1171, -0.0414, -0.0797,  0.0637,  0.1735],\n","        [-0.1356, -0.0478, -0.0919,  0.0736,  0.2004],\n","        [-0.1276, -0.0447, -0.0863,  0.0691,  0.1885],\n","        [-0.1654, -0.0578, -0.1116,  0.0898,  0.2438],\n","        [-0.1551, -0.0542, -0.1049,  0.0841,  0.2291],\n","        [-0.1355, -0.0475, -0.0921,  0.0735,  0.2005],\n","        [-0.1191, -0.0419, -0.0807,  0.0648,  0.1758],\n","        [-0.1408, -0.0492, -0.0951,  0.0766,  0.2074],\n","        [-0.1407, -0.0493, -0.0950,  0.0763,  0.2076],\n","        [-0.1551, -0.0549, -0.1058,  0.0848,  0.2294],\n","        [-0.1477, -0.0519, -0.0998,  0.0800,  0.2184],\n","        [-0.0993, -0.0350, -0.0672,  0.0537,  0.1468]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([2, 0, 0, 0, 4, 4, 4, 2, 3, 4, 3, 1, 3, 4, 4, 4, 1, 3, 2, 0, 0, 3, 4, 4,\n","        2, 4, 1, 4, 2, 4, 2, 0], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [2][1000/1127]\tTime: 0.370 (avg: 0.361)\tData: 0.000 (avg: 0.011)\tLoss: 1.5678 (avg: 1.6063)\n","Step7: save running checkpoint\n","############# Epoch [2] report ############# \n","Time 1: 10.195 s\n","Time 1: 10.195 s\n","Clustering loss: 394.725 \n","ConvNet loss: 712.378 \n","############ End epoch [2] report ########## \n","\n","Step1: get the features for the whole dataset\n","Compute features\n","features: [[ 3.7659278   5.593089    0.8530092  ... -0.46653402  3.9173138\n","   0.39495015]\n"," [ 3.4658132   5.1959147   0.6864691  ... -0.6071319   3.5983393\n","   0.7082277 ]\n"," [ 4.144311    5.667071    0.8329685  ... -0.8498352   3.902563\n","   0.58711284]\n"," ...\n"," [ 3.8801866   5.933527    0.99077845 ... -0.59172356  4.118403\n","   0.6904832 ]\n"," [ 3.992642    5.9216228   0.9006987  ... -0.53111154  4.0895143\n","   0.6510889 ]\n"," [ 2.6069715   3.5448525   0.5350636  ... -0.45023096  2.5495622\n","   0.4129899 ]]\n","Step2: cluster the features\n","k-means loss evolution: [1336.089    713.62384  712.9293   712.71155  712.5844   712.4793\n","  712.4101   712.38367  712.35443  712.3047   712.27734  712.2631\n","  712.2631   712.2631   712.2631   712.2631   712.2631   712.2631\n","  712.2631   712.2631 ]\n","k-means time: 1 s\n","Step3: assign pseudo-labels\n","Step4: uniformly sample for each target\n","Step5: set last fully connected layer\n","Step6: train network with clusters as pseudo-labels\n","len(loader):  1127\n","out:\n","tensor([[ 0.0129,  0.0383, -0.1178, -0.0547,  0.1150],\n","        [ 0.0154,  0.0458, -0.1409, -0.0656,  0.1378],\n","        [ 0.0138,  0.0410, -0.1268, -0.0592,  0.1244],\n","        [ 0.0169,  0.0504, -0.1547, -0.0721,  0.1513],\n","        [ 0.0126,  0.0369, -0.1141, -0.0531,  0.1116],\n","        [ 0.0185,  0.0557, -0.1709, -0.0796,  0.1673],\n","        [ 0.0198,  0.0596, -0.1834, -0.0853,  0.1795],\n","        [ 0.0209,  0.0619, -0.1901, -0.0893,  0.1865],\n","        [ 0.0152,  0.0440, -0.1372, -0.0638,  0.1345],\n","        [ 0.0147,  0.0419, -0.1303, -0.0607,  0.1275],\n","        [ 0.0143,  0.0423, -0.1304, -0.0607,  0.1276],\n","        [ 0.0143,  0.0419, -0.1296, -0.0605,  0.1271],\n","        [ 0.0159,  0.0471, -0.1455, -0.0678,  0.1426],\n","        [ 0.0247,  0.0728, -0.2245, -0.1038,  0.2190],\n","        [ 0.0149,  0.0451, -0.1383, -0.0647,  0.1357],\n","        [ 0.0226,  0.0675, -0.2075, -0.0970,  0.2034],\n","        [ 0.0219,  0.0638, -0.1974, -0.0920,  0.1932],\n","        [ 0.0128,  0.0372, -0.1152, -0.0537,  0.1127],\n","        [ 0.0221,  0.0647, -0.1997, -0.0931,  0.1954],\n","        [ 0.0109,  0.0321, -0.0994, -0.0464,  0.0976],\n","        [ 0.0204,  0.0605, -0.1867, -0.0871,  0.1829],\n","        [ 0.0176,  0.0524, -0.1615, -0.0753,  0.1583],\n","        [ 0.0124,  0.0364, -0.1125, -0.0522,  0.1100],\n","        [ 0.0197,  0.0570, -0.1758, -0.0821,  0.1719],\n","        [ 0.0171,  0.0512, -0.1586, -0.0739,  0.1557],\n","        [ 0.0147,  0.0431, -0.1330, -0.0619,  0.1301],\n","        [ 0.0188,  0.0556, -0.1707, -0.0799,  0.1671],\n","        [ 0.0170,  0.0493, -0.1529, -0.0716,  0.1500],\n","        [ 0.0204,  0.0611, -0.1875, -0.0877,  0.1837],\n","        [ 0.0191,  0.0569, -0.1744, -0.0812,  0.1704],\n","        [ 0.0243,  0.0721, -0.2230, -0.1045,  0.2191],\n","        [ 0.0259,  0.0761, -0.2361, -0.1095,  0.2309]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([1, 4, 3, 0, 1, 4, 0, 0, 3, 2, 3, 1, 1, 2, 3, 4, 2, 2, 0, 1, 3, 1, 3, 2,\n","        3, 0, 1, 3, 3, 1, 2, 4], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [3][0/1127]\tTime: 9.974 (avg: 9.974)\tData: 9.512 (avg: 9.512)\tLoss: 1.6293 (avg: 1.6293)\n","out:\n","tensor([[ 0.0656, -0.0698,  0.0555, -0.0138, -0.0362],\n","        [ 0.0398, -0.0424,  0.0336, -0.0082, -0.0220],\n","        [ 0.0330, -0.0353,  0.0280, -0.0068, -0.0183],\n","        [ 0.0540, -0.0578,  0.0460, -0.0111, -0.0300],\n","        [ 0.0323, -0.0346,  0.0275, -0.0066, -0.0180],\n","        [ 0.0331, -0.0353,  0.0279, -0.0067, -0.0184],\n","        [ 0.0365, -0.0390,  0.0309, -0.0075, -0.0203],\n","        [ 0.0451, -0.0479,  0.0379, -0.0094, -0.0248],\n","        [ 0.0293, -0.0313,  0.0248, -0.0060, -0.0162],\n","        [ 0.0400, -0.0429,  0.0342, -0.0083, -0.0222],\n","        [ 0.0509, -0.0539,  0.0428, -0.0108, -0.0279],\n","        [ 0.0459, -0.0487,  0.0387, -0.0095, -0.0254],\n","        [ 0.0611, -0.0654,  0.0517, -0.0125, -0.0337],\n","        [ 0.0414, -0.0442,  0.0349, -0.0085, -0.0228],\n","        [ 0.0507, -0.0541,  0.0431, -0.0106, -0.0281],\n","        [ 0.0384, -0.0410,  0.0325, -0.0079, -0.0212],\n","        [ 0.0468, -0.0501,  0.0400, -0.0098, -0.0259],\n","        [ 0.0486, -0.0518,  0.0413, -0.0102, -0.0269],\n","        [ 0.0586, -0.0623,  0.0495, -0.0121, -0.0324],\n","        [ 0.0825, -0.0878,  0.0698, -0.0173, -0.0454],\n","        [ 0.0394, -0.0421,  0.0335, -0.0081, -0.0218],\n","        [ 0.0520, -0.0553,  0.0440, -0.0109, -0.0287],\n","        [ 0.0442, -0.0471,  0.0374, -0.0091, -0.0244],\n","        [ 0.0538, -0.0570,  0.0453, -0.0112, -0.0298],\n","        [ 0.0394, -0.0422,  0.0336, -0.0080, -0.0220],\n","        [ 0.0371, -0.0395,  0.0313, -0.0077, -0.0206],\n","        [ 0.0444, -0.0473,  0.0378, -0.0093, -0.0246],\n","        [ 0.0441, -0.0469,  0.0373, -0.0092, -0.0243],\n","        [ 0.0461, -0.0497,  0.0397, -0.0096, -0.0255],\n","        [ 0.0505, -0.0540,  0.0428, -0.0103, -0.0279],\n","        [ 0.0363, -0.0386,  0.0306, -0.0075, -0.0200],\n","        [ 0.0436, -0.0463,  0.0369, -0.0092, -0.0241]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([3, 3, 2, 1, 0, 2, 0, 3, 4, 4, 2, 1, 4, 1, 4, 4, 0, 3, 3, 4, 0, 0, 4, 0,\n","        1, 2, 1, 3, 3, 1, 1, 3], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [3][200/1127]\tTime: 0.353 (avg: 0.414)\tData: 0.000 (avg: 0.064)\tLoss: 1.6170 (avg: 1.6094)\n","out:\n","tensor([[ 0.0151, -0.0136, -0.0256,  0.0351, -0.0107],\n","        [ 0.0090, -0.0079, -0.0150,  0.0206, -0.0065],\n","        [ 0.0056, -0.0050, -0.0094,  0.0130, -0.0041],\n","        [ 0.0119, -0.0105, -0.0198,  0.0270, -0.0084],\n","        [ 0.0114, -0.0101, -0.0190,  0.0261, -0.0082],\n","        [ 0.0055, -0.0050, -0.0092,  0.0127, -0.0039],\n","        [ 0.0068, -0.0061, -0.0115,  0.0158, -0.0049],\n","        [ 0.0107, -0.0096, -0.0182,  0.0251, -0.0078],\n","        [ 0.0094, -0.0082, -0.0154,  0.0209, -0.0066],\n","        [ 0.0139, -0.0122, -0.0231,  0.0318, -0.0100],\n","        [ 0.0075, -0.0066, -0.0125,  0.0171, -0.0054],\n","        [ 0.0071, -0.0063, -0.0118,  0.0161, -0.0051],\n","        [ 0.0160, -0.0142, -0.0269,  0.0370, -0.0116],\n","        [ 0.0112, -0.0098, -0.0187,  0.0255, -0.0080],\n","        [ 0.0101, -0.0089, -0.0168,  0.0230, -0.0072],\n","        [ 0.0228, -0.0203, -0.0378,  0.0522, -0.0164],\n","        [ 0.0072, -0.0064, -0.0120,  0.0165, -0.0051],\n","        [ 0.0122, -0.0110, -0.0205,  0.0283, -0.0087],\n","        [ 0.0094, -0.0083, -0.0155,  0.0213, -0.0067],\n","        [ 0.0087, -0.0077, -0.0147,  0.0201, -0.0063],\n","        [ 0.0090, -0.0080, -0.0150,  0.0206, -0.0064],\n","        [ 0.0121, -0.0107, -0.0201,  0.0275, -0.0086],\n","        [ 0.0094, -0.0082, -0.0158,  0.0214, -0.0067],\n","        [ 0.0205, -0.0181, -0.0343,  0.0470, -0.0147],\n","        [ 0.0191, -0.0170, -0.0323,  0.0444, -0.0138],\n","        [ 0.0052, -0.0047, -0.0089,  0.0122, -0.0038],\n","        [ 0.0116, -0.0102, -0.0193,  0.0263, -0.0082],\n","        [ 0.0132, -0.0117, -0.0219,  0.0302, -0.0095],\n","        [ 0.0104, -0.0093, -0.0173,  0.0236, -0.0073],\n","        [ 0.0131, -0.0118, -0.0222,  0.0305, -0.0094],\n","        [ 0.0120, -0.0106, -0.0199,  0.0271, -0.0084],\n","        [ 0.0118, -0.0106, -0.0199,  0.0275, -0.0086]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([1, 2, 4, 4, 4, 2, 0, 2, 2, 0, 2, 4, 1, 0, 4, 3, 4, 4, 2, 4, 0, 0, 0, 0,\n","        4, 3, 4, 2, 1, 1, 1, 4], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [3][400/1127]\tTime: 0.357 (avg: 0.381)\tData: 0.000 (avg: 0.033)\tLoss: 1.6129 (avg: 1.6094)\n","out:\n","tensor([[ 0.0016,  0.0087, -0.0441, -0.0189,  0.0501],\n","        [ 0.0011,  0.0061, -0.0311, -0.0133,  0.0354],\n","        [ 0.0012,  0.0061, -0.0312, -0.0132,  0.0354],\n","        [ 0.0008,  0.0051, -0.0257, -0.0109,  0.0292],\n","        [ 0.0013,  0.0060, -0.0307, -0.0131,  0.0348],\n","        [ 0.0015,  0.0087, -0.0438, -0.0186,  0.0496],\n","        [ 0.0013,  0.0075, -0.0383, -0.0163,  0.0436],\n","        [ 0.0015,  0.0086, -0.0432, -0.0185,  0.0490],\n","        [ 0.0009,  0.0056, -0.0280, -0.0119,  0.0319],\n","        [ 0.0007,  0.0040, -0.0203, -0.0086,  0.0231],\n","        [ 0.0014,  0.0083, -0.0423, -0.0180,  0.0483],\n","        [ 0.0011,  0.0056, -0.0284, -0.0121,  0.0321],\n","        [ 0.0008,  0.0047, -0.0234, -0.0100,  0.0265],\n","        [ 0.0010,  0.0057, -0.0290, -0.0124,  0.0330],\n","        [ 0.0009,  0.0050, -0.0253, -0.0107,  0.0287],\n","        [ 0.0009,  0.0051, -0.0260, -0.0110,  0.0295],\n","        [ 0.0023,  0.0123, -0.0632, -0.0268,  0.0718],\n","        [ 0.0015,  0.0078, -0.0396, -0.0168,  0.0449],\n","        [ 0.0011,  0.0056, -0.0286, -0.0122,  0.0324],\n","        [ 0.0012,  0.0071, -0.0354, -0.0151,  0.0402],\n","        [ 0.0014,  0.0078, -0.0396, -0.0169,  0.0450],\n","        [ 0.0020,  0.0109, -0.0555, -0.0235,  0.0629],\n","        [ 0.0013,  0.0074, -0.0378, -0.0160,  0.0430],\n","        [ 0.0013,  0.0068, -0.0342, -0.0146,  0.0388],\n","        [ 0.0011,  0.0068, -0.0343, -0.0147,  0.0391],\n","        [ 0.0012,  0.0074, -0.0376, -0.0158,  0.0427],\n","        [ 0.0015,  0.0084, -0.0418, -0.0178,  0.0473],\n","        [ 0.0016,  0.0095, -0.0472, -0.0201,  0.0536],\n","        [ 0.0014,  0.0082, -0.0412, -0.0175,  0.0468],\n","        [ 0.0007,  0.0037, -0.0188, -0.0080,  0.0213],\n","        [ 0.0007,  0.0038, -0.0193, -0.0082,  0.0219],\n","        [ 0.0021,  0.0108, -0.0548, -0.0234,  0.0621]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([4, 2, 2, 0, 1, 3, 3, 2, 3, 0, 4, 1, 1, 3, 4, 0, 0, 2, 2, 0, 4, 1, 4, 3,\n","        0, 1, 3, 4, 2, 1, 2, 2], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [3][600/1127]\tTime: 0.328 (avg: 0.368)\tData: 0.000 (avg: 0.022)\tLoss: 1.6115 (avg: 1.6093)\n","out:\n","tensor([[ 0.0084, -0.0022,  0.0077, -0.0174,  0.0030],\n","        [ 0.0216, -0.0056,  0.0197, -0.0447,  0.0076],\n","        [ 0.0109, -0.0026,  0.0097, -0.0225,  0.0039],\n","        [ 0.0086, -0.0023,  0.0080, -0.0181,  0.0031],\n","        [ 0.0067, -0.0017,  0.0061, -0.0138,  0.0023],\n","        [ 0.0076, -0.0020,  0.0069, -0.0156,  0.0027],\n","        [ 0.0079, -0.0020,  0.0071, -0.0162,  0.0028],\n","        [ 0.0128, -0.0033,  0.0115, -0.0262,  0.0044],\n","        [ 0.0097, -0.0025,  0.0087, -0.0199,  0.0034],\n","        [ 0.0125, -0.0032,  0.0114, -0.0257,  0.0043],\n","        [ 0.0051, -0.0013,  0.0046, -0.0107,  0.0018],\n","        [ 0.0036, -0.0009,  0.0034, -0.0077,  0.0013],\n","        [ 0.0052, -0.0014,  0.0047, -0.0107,  0.0019],\n","        [ 0.0150, -0.0038,  0.0136, -0.0309,  0.0052],\n","        [ 0.0129, -0.0033,  0.0117, -0.0266,  0.0045],\n","        [ 0.0224, -0.0059,  0.0203, -0.0464,  0.0082],\n","        [ 0.0164, -0.0042,  0.0152, -0.0342,  0.0058],\n","        [ 0.0093, -0.0024,  0.0084, -0.0190,  0.0032],\n","        [ 0.0092, -0.0023,  0.0083, -0.0190,  0.0033],\n","        [ 0.0075, -0.0019,  0.0068, -0.0154,  0.0026],\n","        [ 0.0095, -0.0023,  0.0086, -0.0197,  0.0033],\n","        [ 0.0066, -0.0017,  0.0060, -0.0137,  0.0024],\n","        [ 0.0038, -0.0010,  0.0035, -0.0078,  0.0013],\n","        [ 0.0099, -0.0025,  0.0091, -0.0206,  0.0035],\n","        [ 0.0068, -0.0018,  0.0062, -0.0141,  0.0024],\n","        [ 0.0092, -0.0023,  0.0084, -0.0193,  0.0034],\n","        [ 0.0144, -0.0035,  0.0129, -0.0297,  0.0050],\n","        [ 0.0107, -0.0028,  0.0098, -0.0223,  0.0039],\n","        [ 0.0136, -0.0035,  0.0122, -0.0280,  0.0049],\n","        [ 0.0115, -0.0028,  0.0103, -0.0238,  0.0041],\n","        [ 0.0062, -0.0016,  0.0057, -0.0129,  0.0022],\n","        [ 0.0066, -0.0017,  0.0060, -0.0136,  0.0024]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([4, 1, 4, 1, 4, 1, 0, 1, 3, 4, 0, 1, 4, 4, 4, 4, 4, 1, 4, 2, 1, 3, 1, 3,\n","        0, 3, 3, 0, 2, 2, 1, 0], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [3][800/1127]\tTime: 0.312 (avg: 0.363)\tData: 0.000 (avg: 0.017)\tLoss: 1.6099 (avg: 1.6092)\n","out:\n","tensor([[-0.0173,  0.0070, -0.0110, -0.0087,  0.0288],\n","        [-0.0122,  0.0049, -0.0077, -0.0060,  0.0201],\n","        [-0.0139,  0.0055, -0.0087, -0.0068,  0.0230],\n","        [-0.0209,  0.0084, -0.0133, -0.0104,  0.0347],\n","        [-0.0120,  0.0049, -0.0077, -0.0060,  0.0200],\n","        [-0.0253,  0.0101, -0.0160, -0.0126,  0.0420],\n","        [-0.0135,  0.0054, -0.0086, -0.0067,  0.0223],\n","        [-0.0159,  0.0064, -0.0100, -0.0079,  0.0263],\n","        [-0.0349,  0.0139, -0.0222, -0.0172,  0.0578],\n","        [-0.0227,  0.0090, -0.0143, -0.0112,  0.0376],\n","        [-0.0186,  0.0074, -0.0119, -0.0092,  0.0308],\n","        [-0.0210,  0.0084, -0.0133, -0.0105,  0.0348],\n","        [-0.0213,  0.0085, -0.0135, -0.0106,  0.0354],\n","        [-0.0106,  0.0042, -0.0067, -0.0052,  0.0176],\n","        [-0.0193,  0.0075, -0.0122, -0.0095,  0.0321],\n","        [-0.0233,  0.0093, -0.0146, -0.0114,  0.0383],\n","        [-0.0241,  0.0095, -0.0153, -0.0120,  0.0402],\n","        [-0.0214,  0.0084, -0.0134, -0.0106,  0.0355],\n","        [-0.0123,  0.0049, -0.0078, -0.0060,  0.0203],\n","        [-0.0115,  0.0046, -0.0072, -0.0057,  0.0190],\n","        [-0.0070,  0.0027, -0.0044, -0.0035,  0.0118],\n","        [-0.0267,  0.0107, -0.0171, -0.0133,  0.0445],\n","        [-0.0129,  0.0052, -0.0081, -0.0064,  0.0214],\n","        [-0.0281,  0.0112, -0.0177, -0.0139,  0.0465],\n","        [-0.0177,  0.0070, -0.0112, -0.0088,  0.0294],\n","        [-0.0211,  0.0083, -0.0132, -0.0104,  0.0349],\n","        [-0.0325,  0.0129, -0.0205, -0.0161,  0.0539],\n","        [-0.0119,  0.0048, -0.0076, -0.0060,  0.0198],\n","        [-0.0191,  0.0076, -0.0120, -0.0094,  0.0314],\n","        [-0.0085,  0.0034, -0.0054, -0.0042,  0.0141],\n","        [-0.0141,  0.0056, -0.0089, -0.0070,  0.0233],\n","        [-0.0248,  0.0098, -0.0157, -0.0122,  0.0412]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([4, 4, 4, 2, 0, 3, 0, 2, 4, 3, 4, 1, 3, 0, 3, 2, 2, 4, 3, 0, 1, 1, 4, 3,\n","        3, 0, 4, 2, 3, 3, 0, 4], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [3][1000/1127]\tTime: 0.388 (avg: 0.360)\tData: 0.000 (avg: 0.014)\tLoss: 1.6061 (avg: 1.6090)\n","Step7: save running checkpoint\n","############# Epoch [3] report ############# \n","Time 1: 10.639 s\n","Time 1: 10.639 s\n","Clustering loss: 393.601 \n","ConvNet loss: 712.263 \n","############ End epoch [3] report ########## \n","\n","Step1: get the features for the whole dataset\n","Compute features\n","features: [[ 0.78568697  1.2963662   0.254448   ... -0.18442914  0.7562714\n","   0.3167951 ]\n"," [ 0.89849806  1.4068073   0.27403948 ... -0.19237006  0.8152313\n","   0.31153178]\n"," [ 1.9227529   2.9230232   0.6220371  ... -0.2164316   1.6166575\n","   0.8355315 ]\n"," ...\n"," [ 1.405283    2.2405689   0.46508166 ... -0.24293295  1.2417018\n","   0.60616815]\n"," [ 1.0280874   1.5610957   0.3073141  ... -0.2816089   0.965786\n","   0.34957653]\n"," [ 0.7773589   1.2749636   0.24993901 ... -0.23075469  0.71430445\n","   0.3348129 ]]\n","Step2: cluster the features\n","k-means loss evolution: [1346.7627   713.15295  711.61005  710.67596  709.8842   709.26373\n","  708.8932   708.6448   708.5166   708.4713   708.42566  708.39996\n","  708.38574  708.38574  708.38574  708.38574  708.38574  708.38574\n","  708.38574  708.38574]\n","k-means time: 1 s\n","Step3: assign pseudo-labels\n","Step4: uniformly sample for each target\n","Step5: set last fully connected layer\n","Step6: train network with clusters as pseudo-labels\n","len(loader):  1127\n","out:\n","tensor([[ 0.0069,  0.0012, -0.0029, -0.0040, -0.0013],\n","        [ 0.0155,  0.0027, -0.0063, -0.0093, -0.0029],\n","        [ 0.0118,  0.0020, -0.0049, -0.0070, -0.0021],\n","        [ 0.0137,  0.0023, -0.0055, -0.0081, -0.0026],\n","        [ 0.0193,  0.0035, -0.0080, -0.0116, -0.0035],\n","        [ 0.0166,  0.0028, -0.0068, -0.0098, -0.0031],\n","        [ 0.0137,  0.0024, -0.0056, -0.0081, -0.0026],\n","        [ 0.0142,  0.0025, -0.0059, -0.0085, -0.0025],\n","        [ 0.0094,  0.0016, -0.0039, -0.0056, -0.0017],\n","        [ 0.0072,  0.0013, -0.0030, -0.0043, -0.0013],\n","        [ 0.0133,  0.0023, -0.0056, -0.0079, -0.0023],\n","        [ 0.0102,  0.0018, -0.0041, -0.0060, -0.0020],\n","        [ 0.0093,  0.0016, -0.0038, -0.0055, -0.0017],\n","        [ 0.0119,  0.0020, -0.0049, -0.0071, -0.0021],\n","        [ 0.0132,  0.0022, -0.0054, -0.0079, -0.0024],\n","        [ 0.0076,  0.0013, -0.0031, -0.0045, -0.0013],\n","        [ 0.0120,  0.0020, -0.0049, -0.0071, -0.0021],\n","        [ 0.0091,  0.0016, -0.0038, -0.0054, -0.0017],\n","        [ 0.0048,  0.0008, -0.0019, -0.0029, -0.0009],\n","        [ 0.0099,  0.0017, -0.0041, -0.0059, -0.0018],\n","        [ 0.0162,  0.0027, -0.0067, -0.0096, -0.0029],\n","        [ 0.0076,  0.0013, -0.0031, -0.0045, -0.0014],\n","        [ 0.0171,  0.0030, -0.0071, -0.0100, -0.0032],\n","        [ 0.0138,  0.0024, -0.0058, -0.0081, -0.0026],\n","        [ 0.0130,  0.0023, -0.0053, -0.0078, -0.0024],\n","        [ 0.0251,  0.0040, -0.0101, -0.0147, -0.0047],\n","        [ 0.0137,  0.0024, -0.0057, -0.0082, -0.0024],\n","        [ 0.0065,  0.0011, -0.0027, -0.0039, -0.0012],\n","        [ 0.0040,  0.0007, -0.0016, -0.0024, -0.0007],\n","        [ 0.0171,  0.0030, -0.0070, -0.0103, -0.0031],\n","        [ 0.0066,  0.0012, -0.0028, -0.0039, -0.0012],\n","        [ 0.0108,  0.0018, -0.0044, -0.0064, -0.0020]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([4, 1, 0, 4, 0, 3, 0, 2, 2, 4, 0, 0, 4, 4, 3, 1, 4, 4, 3, 2, 3, 3, 1, 0,\n","        3, 1, 3, 3, 4, 4, 3, 4], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [4][0/1127]\tTime: 10.994 (avg: 10.994)\tData: 10.509 (avg: 10.509)\tLoss: 1.6094 (avg: 1.6094)\n","out:\n","tensor([[-0.4361,  0.0245, -0.4109,  0.3078,  0.3311],\n","        [-0.4659,  0.0257, -0.4391,  0.3288,  0.3540],\n","        [-0.5035,  0.0282, -0.4739,  0.3552,  0.3824],\n","        [-0.4462,  0.0253, -0.4196,  0.3149,  0.3381],\n","        [-0.5197,  0.0297, -0.4889,  0.3667,  0.3938],\n","        [-0.4677,  0.0259, -0.4416,  0.3298,  0.3561],\n","        [-0.4104,  0.0224, -0.3880,  0.2895,  0.3133],\n","        [-0.6022,  0.0339, -0.5665,  0.4252,  0.4565],\n","        [-0.3279,  0.0184, -0.3088,  0.2316,  0.2488],\n","        [-0.3251,  0.0182, -0.3064,  0.2295,  0.2471],\n","        [-0.5360,  0.0296, -0.5059,  0.3785,  0.4078],\n","        [-0.3367,  0.0185, -0.3176,  0.2377,  0.2562],\n","        [-0.4831,  0.0270, -0.4547,  0.3408,  0.3664],\n","        [-0.3286,  0.0183, -0.3101,  0.2322,  0.2498],\n","        [-0.4507,  0.0250, -0.4254,  0.3180,  0.3430],\n","        [-0.5252,  0.0296, -0.4949,  0.3702,  0.3989],\n","        [-0.4620,  0.0263, -0.4346,  0.3262,  0.3501],\n","        [-0.5572,  0.0313, -0.5237,  0.3938,  0.4218],\n","        [-0.4095,  0.0231, -0.3855,  0.2887,  0.3107],\n","        [-0.4589,  0.0259, -0.4323,  0.3237,  0.3487],\n","        [-0.5062,  0.0282, -0.4765,  0.3570,  0.3842],\n","        [-0.4538,  0.0257, -0.4265,  0.3204,  0.3434],\n","        [-0.6292,  0.0353, -0.5916,  0.4440,  0.4771],\n","        [-0.5200,  0.0291, -0.4895,  0.3673,  0.3944],\n","        [-0.4312,  0.0242, -0.4065,  0.3045,  0.3277],\n","        [-0.5071,  0.0284, -0.4765,  0.3579,  0.3841],\n","        [-0.4510,  0.0253, -0.4241,  0.3184,  0.3417],\n","        [-0.4534,  0.0255, -0.4265,  0.3196,  0.3439],\n","        [-0.3665,  0.0205, -0.3456,  0.2586,  0.2786],\n","        [-0.3994,  0.0225, -0.3764,  0.2817,  0.3035],\n","        [-0.3944,  0.0220, -0.3714,  0.2784,  0.2996],\n","        [-0.4269,  0.0240, -0.4019,  0.3018,  0.3239]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([1, 2, 3, 3, 3, 1, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 4, 1, 0, 3, 1, 3, 1,\n","        4, 3, 1, 3, 3, 2, 3, 4], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [4][200/1127]\tTime: 0.334 (avg: 0.427)\tData: 0.000 (avg: 0.053)\tLoss: 1.4667 (avg: 1.5797)\n","out:\n","tensor([[-0.2196, -0.1958, -0.0828,  0.3043,  0.0926],\n","        [-0.3260, -0.2909, -0.1227,  0.4516,  0.1376],\n","        [-0.2136, -0.1901, -0.0807,  0.2956,  0.0902],\n","        [-0.1515, -0.1351, -0.0571,  0.2098,  0.0639],\n","        [-0.4662, -0.4162, -0.1753,  0.6463,  0.1964],\n","        [-0.2924, -0.2607, -0.1101,  0.4050,  0.1233],\n","        [-0.2820, -0.2511, -0.1064,  0.3903,  0.1190],\n","        [-0.1952, -0.1739, -0.0735,  0.2701,  0.0824],\n","        [-0.3746, -0.3338, -0.1410,  0.5184,  0.1581],\n","        [-0.1731, -0.1543, -0.0652,  0.2397,  0.0730],\n","        [-0.2133, -0.1898, -0.0806,  0.2950,  0.0901],\n","        [-0.3495, -0.3120, -0.1318,  0.4844,  0.1477],\n","        [-0.3827, -0.3407, -0.1445,  0.5294,  0.1617],\n","        [-0.4455, -0.3969, -0.1679,  0.6165,  0.1881],\n","        [-0.4141, -0.3699, -0.1556,  0.5742,  0.1745],\n","        [-0.3959, -0.3524, -0.1493,  0.5477,  0.1669],\n","        [-0.2597, -0.2316, -0.0978,  0.3596,  0.1096],\n","        [-0.2699, -0.2408, -0.1017,  0.3740,  0.1140],\n","        [-0.3364, -0.2993, -0.1270,  0.4654,  0.1420],\n","        [-0.1861, -0.1664, -0.0698,  0.2581,  0.0784],\n","        [-0.4316, -0.3848, -0.1623,  0.5979,  0.1814],\n","        [-0.3706, -0.3299, -0.1399,  0.5130,  0.1562],\n","        [-0.3225, -0.2876, -0.1214,  0.4466,  0.1359],\n","        [-0.3406, -0.3041, -0.1279,  0.4721,  0.1436],\n","        [-0.4069, -0.3633, -0.1534,  0.5640,  0.1720],\n","        [-0.1794, -0.1601, -0.0675,  0.2486,  0.0757],\n","        [-0.3955, -0.3528, -0.1490,  0.5480,  0.1666],\n","        [-0.2413, -0.2147, -0.0910,  0.3339,  0.1017],\n","        [-0.3865, -0.3444, -0.1456,  0.5349,  0.1632],\n","        [-0.2790, -0.2478, -0.1055,  0.3855,  0.1178],\n","        [-0.4198, -0.3735, -0.1584,  0.5809,  0.1770],\n","        [-0.3005, -0.2674, -0.1134,  0.4160,  0.1266]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([3, 3, 0, 0, 3, 1, 1, 3, 1, 1, 0, 2, 3, 3, 4, 1, 2, 3, 1, 2, 3, 4, 4, 3,\n","        3, 1, 3, 1, 1, 3, 3, 1], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [4][400/1127]\tTime: 0.407 (avg: 0.394)\tData: 0.000 (avg: 0.027)\tLoss: 1.5221 (avg: 1.5704)\n","out:\n","tensor([[-2.5786e-03, -1.7975e-01, -2.8025e-01, -1.2831e-02,  6.1204e-01],\n","        [-3.6236e-03, -2.0774e-01, -3.2470e-01, -1.4506e-02,  7.0823e-01],\n","        [-5.8293e-04, -6.7399e-02, -1.0473e-01, -5.0532e-03,  2.2885e-01],\n","        [-1.9393e-03, -1.0107e-01, -1.5801e-01, -6.8635e-03,  3.4438e-01],\n","        [-2.9254e-03, -1.8660e-01, -2.9113e-01, -1.3249e-02,  6.3529e-01],\n","        [-2.3298e-04, -3.0298e-02, -4.7048e-02, -2.2697e-03,  1.0285e-01],\n","        [-1.3257e-03, -1.2291e-01, -1.9113e-01, -8.9891e-03,  4.1752e-01],\n","        [-8.2842e-04, -6.0939e-02, -9.4973e-02, -4.4301e-03,  2.0738e-01],\n","        [-5.2627e-04, -5.1651e-02, -8.0403e-02, -3.8169e-03,  1.7562e-01],\n","        [-7.0167e-04, -4.6161e-02, -7.1998e-02, -3.2775e-03,  1.5712e-01],\n","        [-1.0273e-03, -9.9424e-02, -1.5446e-01, -7.3460e-03,  3.3774e-01],\n","        [-3.5716e-03, -2.2817e-01, -3.5624e-01, -1.6096e-02,  7.7754e-01],\n","        [-1.1641e-03, -1.0237e-01, -1.5948e-01, -7.3975e-03,  3.4830e-01],\n","        [-6.4191e-04, -5.3558e-02, -8.3311e-02, -3.9150e-03,  1.8204e-01],\n","        [-8.8600e-04, -5.5010e-02, -8.5910e-02, -3.8729e-03,  1.8752e-01],\n","        [-2.1600e-03, -2.4390e-01, -3.7942e-01, -1.8305e-02,  8.2962e-01],\n","        [-1.3065e-03, -1.2645e-01, -1.9651e-01, -9.3067e-03,  4.2949e-01],\n","        [-1.0246e-03, -1.3341e-01, -2.0733e-01, -1.0073e-02,  4.5319e-01],\n","        [-4.5528e-04, -5.7769e-02, -8.9720e-02, -4.3375e-03,  1.9614e-01],\n","        [-2.4470e-03, -1.7451e-01, -2.7212e-01, -1.2680e-02,  5.9458e-01],\n","        [-2.8019e-03, -3.2580e-01, -5.0580e-01, -2.4116e-02,  1.1059e+00],\n","        [-6.8265e-04, -6.3415e-02, -9.8673e-02, -4.6910e-03,  2.1560e-01],\n","        [-5.0363e-04, -5.1753e-02, -8.0600e-02, -3.8467e-03,  1.7616e-01],\n","        [-2.0360e-03, -1.5017e-01, -2.3413e-01, -1.0815e-02,  5.1135e-01],\n","        [-5.1557e-04, -4.5285e-02, -7.0472e-02, -3.2733e-03,  1.5393e-01],\n","        [-4.8615e-04, -3.9605e-02, -6.1625e-02, -2.9037e-03,  1.3462e-01],\n","        [-2.7425e-03, -2.2209e-01, -3.4607e-01, -1.5968e-02,  7.5542e-01],\n","        [-1.3754e-03, -1.1485e-01, -1.7899e-01, -8.3999e-03,  3.9096e-01],\n","        [-3.6389e-04, -2.7348e-02, -4.2690e-02, -1.9736e-03,  9.3110e-02],\n","        [-4.5311e-04, -4.3131e-02, -6.7137e-02, -3.1746e-03,  1.4667e-01],\n","        [-9.5385e-04, -7.7108e-02, -1.2007e-01, -5.6405e-03,  2.6250e-01],\n","        [-8.9569e-04, -8.4011e-02, -1.3067e-01, -6.2393e-03,  2.8577e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([3, 3, 1, 1, 3, 4, 1, 4, 2, 0, 3, 3, 1, 1, 3, 4, 3, 1, 1, 3, 3, 0, 1, 3,\n","        4, 3, 3, 3, 2, 0, 3, 3], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [4][600/1127]\tTime: 0.372 (avg: 0.381)\tData: 0.000 (avg: 0.018)\tLoss: 1.6463 (avg: 1.5615)\n","out:\n","tensor([[-0.2900,  0.0673, -0.2246,  0.2775,  0.0407],\n","        [-1.3621,  0.3156, -1.0542,  1.3026,  0.1913],\n","        [-0.7943,  0.1841, -0.6148,  0.7596,  0.1116],\n","        [-1.1012,  0.2552, -0.8524,  1.0533,  0.1546],\n","        [-1.3374,  0.3096, -1.0350,  1.2789,  0.1879],\n","        [-0.7001,  0.1622, -0.5419,  0.6697,  0.0983],\n","        [-0.7030,  0.1630, -0.5443,  0.6725,  0.0988],\n","        [-0.5169,  0.1198, -0.4001,  0.4944,  0.0725],\n","        [-0.3804,  0.0881, -0.2944,  0.3636,  0.0535],\n","        [-0.3778,  0.0876, -0.2926,  0.3616,  0.0531],\n","        [-0.1618,  0.0375, -0.1253,  0.1548,  0.0227],\n","        [-0.7112,  0.1647, -0.5505,  0.6803,  0.0998],\n","        [-0.7725,  0.1788, -0.5980,  0.7389,  0.1085],\n","        [-0.2511,  0.0583, -0.1945,  0.2403,  0.0353],\n","        [-1.0137,  0.2347, -0.7847,  0.9697,  0.1424],\n","        [-0.4937,  0.1144, -0.3823,  0.4724,  0.0694],\n","        [-0.4506,  0.1044, -0.3489,  0.4311,  0.0633],\n","        [-1.1747,  0.2723, -0.9094,  1.1236,  0.1652],\n","        [-0.4215,  0.0979, -0.3266,  0.4035,  0.0592],\n","        [-1.3306,  0.3087, -1.0303,  1.2729,  0.1869],\n","        [-1.0298,  0.2387, -0.7973,  0.9852,  0.1447],\n","        [-0.7011,  0.1624, -0.5428,  0.6709,  0.0985],\n","        [-1.7779,  0.4114, -1.3759,  1.7002,  0.2498],\n","        [-0.9879,  0.2287, -0.7645,  0.9449,  0.1386],\n","        [-0.8089,  0.1873, -0.6260,  0.7736,  0.1136],\n","        [-0.2789,  0.0645, -0.2158,  0.2666,  0.0392],\n","        [-0.8511,  0.1974, -0.6590,  0.8144,  0.1196],\n","        [-0.3445,  0.0797, -0.2666,  0.3293,  0.0484],\n","        [-1.3765,  0.3187, -1.0652,  1.3162,  0.1933],\n","        [-0.9204,  0.2134, -0.7128,  0.8808,  0.1292],\n","        [-0.8805,  0.2045, -0.6820,  0.8427,  0.1236],\n","        [-0.6443,  0.1496, -0.4991,  0.6168,  0.0905]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([2, 4, 3, 3, 3, 4, 4, 2, 3, 0, 2, 4, 1, 4, 1, 4, 0, 3, 3, 4, 4, 0, 3, 3,\n","        3, 2, 1, 2, 3, 3, 3, 1], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [4][800/1127]\tTime: 0.386 (avg: 0.374)\tData: 0.000 (avg: 0.014)\tLoss: 1.3992 (avg: 1.5509)\n","out:\n","tensor([[-5.2756e-01,  1.2974e-01, -3.5642e-01,  3.5693e-02,  2.5631e-01],\n","        [-3.3302e-01,  8.1948e-02, -2.2498e-01,  2.2328e-02,  1.6137e-01],\n","        [-1.5753e+00,  3.8783e-01, -1.0642e+00,  1.0514e-01,  7.6232e-01],\n","        [-1.9495e+00,  4.7988e-01, -1.3172e+00,  1.3004e-01,  9.4285e-01],\n","        [-5.1804e-01,  1.2747e-01, -3.4998e-01,  3.4896e-02,  2.5155e-01],\n","        [-1.0238e+00,  2.5204e-01, -6.9171e-01,  6.8366e-02,  4.9557e-01],\n","        [-1.0051e+00,  2.4746e-01, -6.7901e-01,  6.7043e-02,  4.8616e-01],\n","        [-3.5270e-01,  8.6868e-02, -2.3829e-01,  2.3420e-02,  1.7034e-01],\n","        [-6.8243e-01,  1.6806e-01, -4.6106e-01,  4.5397e-02,  3.2981e-01],\n","        [-1.0870e+00,  2.6772e-01, -7.3434e-01,  7.2311e-02,  5.2565e-01],\n","        [-2.6501e-02,  6.4985e-03, -1.7899e-02,  1.8602e-03,  1.3050e-02],\n","        [-7.5662e-01,  1.8644e-01, -5.1113e-01,  5.0339e-02,  3.6614e-01],\n","        [-6.2473e-01,  1.5368e-01, -4.2207e-01,  4.1987e-02,  3.0268e-01],\n","        [-7.5558e-01,  1.8602e-01, -5.1046e-01,  5.0414e-02,  3.6563e-01],\n","        [-7.2793e-01,  1.7919e-01, -4.9177e-01,  4.8824e-02,  3.5287e-01],\n","        [-6.8579e-02,  1.6843e-02, -4.6326e-02,  4.7364e-03,  3.3604e-02],\n","        [-1.0846e+00,  2.6704e-01, -7.3280e-01,  7.2701e-02,  5.2575e-01],\n","        [-9.0298e-01,  2.2238e-01, -6.1002e-01,  6.0084e-02,  4.3685e-01],\n","        [-3.4049e-01,  8.3824e-02, -2.3004e-01,  2.2806e-02,  1.6507e-01],\n","        [-6.0300e-01,  1.4841e-01, -4.0741e-01,  4.0490e-02,  2.9220e-01],\n","        [-6.4233e-01,  1.5815e-01, -4.3395e-01,  4.2853e-02,  3.1076e-01],\n","        [-9.2167e-01,  2.2670e-01, -6.2269e-01,  6.1950e-02,  4.4686e-01],\n","        [-7.8443e-01,  1.9294e-01, -5.2996e-01,  5.3039e-02,  3.8112e-01],\n","        [-2.9813e+00,  7.3417e-01, -2.0141e+00,  1.9882e-01,  1.4431e+00],\n","        [-3.2890e-01,  8.0952e-02, -2.2219e-01,  2.2077e-02,  1.5947e-01],\n","        [-1.0079e+00,  2.4824e-01, -6.8091e-01,  6.7255e-02,  4.8768e-01],\n","        [-6.8064e-01,  1.6759e-01, -4.5982e-01,  4.5344e-02,  3.2929e-01],\n","        [-7.1456e-01,  1.7585e-01, -4.8273e-01,  4.8035e-02,  3.4666e-01],\n","        [-5.7571e-01,  1.4174e-01, -3.8894e-01,  3.8473e-02,  2.7882e-01],\n","        [-3.1044e-01,  7.6433e-02, -2.0973e-01,  2.0696e-02,  1.5018e-01],\n","        [-2.9325e-01,  7.2218e-02, -1.9810e-01,  1.9502e-02,  1.4176e-01],\n","        [-8.9348e-01,  2.1990e-01, -6.0366e-01,  6.0138e-02,  4.3355e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([2, 1, 1, 3, 4, 4, 3, 0, 1, 4, 2, 4, 1, 2, 4, 0, 3, 4, 2, 4, 1, 4, 3, 3,\n","        2, 3, 1, 2, 1, 2, 1, 4], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [4][1000/1127]\tTime: 0.301 (avg: 0.370)\tData: 0.000 (avg: 0.011)\tLoss: 1.4971 (avg: 1.5350)\n","Step7: save running checkpoint\n","############# Epoch [4] report ############# \n","Time 1: 11.278 s\n","Time 1: 11.278 s\n","Clustering loss: 404.199 \n","ConvNet loss: 708.386 \n","############ End epoch [4] report ########## \n","\n","Step1: get the features for the whole dataset\n","Compute features\n","features: [[32.14131  26.555817 45.989037 ... 44.75984  34.89602  37.55396 ]\n"," [25.73711  21.21534  36.888145 ... 35.84979  28.003912 30.061737]\n"," [25.49804  21.023151 36.556767 ... 35.349957 27.603409 29.84863 ]\n"," ...\n"," [29.604435 24.4123   42.309784 ... 41.10251  32.01556  34.470226]\n"," [17.65564  14.542245 25.249046 ... 24.500477 19.05808  20.640749]\n"," [30.981682 25.546415 44.414726 ... 43.088226 33.546524 36.274   ]]\n","Step2: cluster the features\n","k-means loss evolution: [1268.6061   663.8999   657.02905  655.42084  654.9628   654.7629\n","  654.6498   654.60077  654.5684   654.5684   654.5684   654.5684\n","  654.5684   654.5684   654.5684   654.5684   654.5684   654.5684\n","  654.5684   654.5684 ]\n","k-means time: 1 s\n","Step3: assign pseudo-labels\n","Step4: uniformly sample for each target\n","Step5: set last fully connected layer\n","Step6: train network with clusters as pseudo-labels\n","len(loader):  1127\n","out:\n","tensor([[-1.7495e-01,  7.2075e-05, -1.6836e-01,  2.0471e-01, -1.2701e-02],\n","        [-1.1625e+00,  1.5334e-04, -1.1187e+00,  1.3603e+00, -8.4421e-02],\n","        [-1.3951e+00, -5.0496e-04, -1.3426e+00,  1.6289e+00, -1.0090e-01],\n","        [-7.3373e-01, -3.3810e-04, -7.0610e-01,  8.5655e-01, -5.3044e-02],\n","        [-3.0384e-02,  7.2924e-05, -2.9231e-02,  3.5801e-02, -2.2340e-03],\n","        [-1.3323e-01,  1.2409e-04, -1.2821e-01,  1.5626e-01, -9.7086e-03],\n","        [-2.7522e-01, -2.3877e-05, -2.6486e-01,  3.2164e-01, -1.9943e-02],\n","        [-2.5539e-01, -4.0911e-05, -2.4576e-01,  2.9856e-01, -1.8516e-02],\n","        [-5.6267e-01,  1.0980e-04, -5.4147e-01,  6.5823e-01, -4.0822e-02],\n","        [-5.6808e-01, -3.3231e-04, -5.4670e-01,  6.6303e-01, -4.1064e-02],\n","        [-1.4898e+00, -8.9052e-04, -1.4338e+00,  1.7382e+00, -1.0763e-01],\n","        [-3.9203e-01, -1.8092e-05, -3.7727e-01,  4.5817e-01, -2.8407e-02],\n","        [-1.5065e+00, -4.6763e-04, -1.4498e+00,  1.7600e+00, -1.0904e-01],\n","        [-9.9101e-01, -2.7167e-05, -9.5370e-01,  1.1586e+00, -7.1819e-02],\n","        [-1.9295e+00, -4.2305e-04, -1.8568e+00,  2.2552e+00, -1.3986e-01],\n","        [-1.2574e+00, -3.4828e-04, -1.2101e+00,  1.4690e+00, -9.1077e-02],\n","        [-4.9899e-01,  3.3845e-04, -4.8016e-01,  5.8491e-01, -3.6345e-02],\n","        [-6.0635e-01, -1.5508e-04, -5.8354e-01,  7.0802e-01, -4.3867e-02],\n","        [-2.4606e-01,  8.6728e-06, -2.3679e-01,  2.8760e-01, -1.7843e-02],\n","        [-4.9815e-02,  1.3546e-04, -4.7927e-02,  5.8753e-02, -3.6612e-03],\n","        [-7.5722e-01, -2.8157e-04, -7.2871e-01,  8.8413e-01, -5.4788e-02],\n","        [-6.7497e-02,  1.7536e-04, -6.4942e-02,  7.9572e-02, -4.9605e-03],\n","        [-6.9534e-01, -3.8758e-04, -6.6918e-01,  8.1142e-01, -5.0219e-02],\n","        [-7.2514e-01, -2.9641e-05, -6.9781e-01,  8.4776e-01, -5.2585e-02],\n","        [-9.3746e-01, -7.8461e-05, -9.0215e-01,  1.0959e+00, -6.7921e-02],\n","        [-2.0065e-01,  1.7314e-04, -1.9308e-01,  2.3523e-01, -1.4611e-02],\n","        [-2.2967e+00, -2.9870e-04, -2.2103e+00,  2.6838e+00, -1.6635e-01],\n","        [-7.7657e-02,  1.4366e-04, -7.4723e-02,  9.1294e-02, -5.6812e-03],\n","        [-6.2700e-01, -7.4183e-05, -6.0339e-01,  7.3285e-01, -4.5444e-02],\n","        [-8.8899e-01, -2.8409e-04, -8.5553e-01,  1.0382e+00, -6.4342e-02],\n","        [-2.3997e+00,  7.0831e-04, -2.3093e+00,  2.8093e+00, -1.7431e-01],\n","        [-6.6745e-01, -1.3223e-04, -6.4233e-01,  7.7980e-01, -4.8370e-02]],\n","       device='cuda:0', grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([3, 0, 4, 2, 2, 1, 1, 4, 4, 3, 1, 1, 4, 0, 3, 3, 2, 3, 1, 3, 1, 2, 3, 4,\n","        3, 1, 2, 1, 4, 2, 0, 1], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [5][0/1127]\tTime: 10.936 (avg: 10.936)\tData: 10.410 (avg: 10.410)\tLoss: 1.8546 (avg: 1.8546)\n","out:\n","tensor([[-0.0640, -0.0786, -0.0731,  0.1180,  0.0904],\n","        [-0.0226, -0.0278, -0.0259,  0.0418,  0.0320],\n","        [-0.0910, -0.1118, -0.1040,  0.1677,  0.1286],\n","        [-0.0473, -0.0580, -0.0540,  0.0871,  0.0668],\n","        [-0.1179, -0.1449, -0.1347,  0.2173,  0.1666],\n","        [-0.0612, -0.0753, -0.0700,  0.1129,  0.0866],\n","        [-0.0590, -0.0725, -0.0675,  0.1088,  0.0834],\n","        [-0.0368, -0.0452, -0.0421,  0.0679,  0.0521],\n","        [-0.0136, -0.0167, -0.0156,  0.0252,  0.0193],\n","        [-0.0561, -0.0689, -0.0641,  0.1034,  0.0792],\n","        [-0.0310, -0.0380, -0.0354,  0.0571,  0.0437],\n","        [-0.0673, -0.0827, -0.0770,  0.1241,  0.0952],\n","        [-0.0852, -0.1047, -0.0974,  0.1571,  0.1204],\n","        [-0.0866, -0.1064, -0.0990,  0.1597,  0.1224],\n","        [-0.1051, -0.1290, -0.1200,  0.1936,  0.1484],\n","        [-0.0189, -0.0231, -0.0216,  0.0348,  0.0266],\n","        [-0.0287, -0.0353, -0.0328,  0.0530,  0.0406],\n","        [-0.0338, -0.0416, -0.0387,  0.0624,  0.0478],\n","        [-0.0663, -0.0814, -0.0757,  0.1221,  0.0936],\n","        [-0.0440, -0.0540, -0.0502,  0.0810,  0.0621],\n","        [-0.0123, -0.0151, -0.0141,  0.0227,  0.0174],\n","        [-0.0190, -0.0233, -0.0217,  0.0350,  0.0268],\n","        [-0.0521, -0.0641, -0.0596,  0.0961,  0.0737],\n","        [-0.0861, -0.1058, -0.0984,  0.1588,  0.1217],\n","        [-0.0646, -0.0794, -0.0738,  0.1191,  0.0913],\n","        [-0.0763, -0.0938, -0.0872,  0.1406,  0.1078],\n","        [-0.0496, -0.0609, -0.0566,  0.0914,  0.0700],\n","        [-0.0401, -0.0492, -0.0458,  0.0739,  0.0567],\n","        [-0.0675, -0.0830, -0.0772,  0.1245,  0.0954],\n","        [-0.0665, -0.0817, -0.0760,  0.1226,  0.0939],\n","        [-0.0615, -0.0755, -0.0702,  0.1133,  0.0868],\n","        [-0.0980, -0.1204, -0.1120,  0.1807,  0.1385]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([4, 0, 3, 2, 0, 0, 2, 1, 1, 1, 4, 2, 1, 3, 4, 3, 2, 4, 0, 2, 1, 1, 1, 1,\n","        0, 3, 1, 1, 1, 0, 0, 2], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [5][200/1127]\tTime: 0.380 (avg: 0.420)\tData: 0.000 (avg: 0.061)\tLoss: 1.6324 (avg: 1.6103)\n","out:\n","tensor([[-3.8948e-01, -1.6077e-01, -6.4039e-02,  4.3136e-02,  3.7361e-01],\n","        [-2.6626e-01, -1.0977e-01, -4.3655e-02,  2.9479e-02,  2.5615e-01],\n","        [-2.0516e-01, -8.4563e-02, -3.3640e-02,  2.2716e-02,  1.9745e-01],\n","        [-3.7915e-03, -1.5491e-03, -6.1333e-04,  4.1891e-04,  3.7124e-03],\n","        [-4.3250e-01, -1.7842e-01, -7.0977e-02,  4.7886e-02,  4.1575e-01],\n","        [-3.2260e-01, -1.3305e-01, -5.2950e-02,  3.5745e-02,  3.1029e-01],\n","        [-2.7309e-01, -1.1263e-01, -4.4808e-02,  3.0236e-02,  2.6269e-01],\n","        [-1.3909e-01, -5.7282e-02, -2.2758e-02,  1.5409e-02,  1.3419e-01],\n","        [-1.5491e-01, -6.3888e-02, -2.5414e-02,  1.7144e-02,  1.4881e-01],\n","        [-1.3739e-01, -5.6609e-02, -2.2508e-02,  1.5208e-02,  1.3224e-01],\n","        [-7.5406e-01, -3.1092e-01, -1.2366e-01,  8.3506e-02,  7.2507e-01],\n","        [-3.2080e-01, -1.3237e-01, -5.2690e-02,  3.5526e-02,  3.0807e-01],\n","        [-1.9046e-01, -7.8559e-02, -3.1258e-02,  2.1091e-02,  1.8311e-01],\n","        [-2.0951e-01, -8.6407e-02, -3.4387e-02,  2.3199e-02,  2.0130e-01],\n","        [-3.8274e-01, -1.5780e-01, -6.2814e-02,  4.2364e-02,  3.6825e-01],\n","        [-2.0527e-01, -8.4641e-02, -3.3695e-02,  2.2727e-02,  1.9747e-01],\n","        [-2.7014e-01, -1.1137e-01, -4.4320e-02,  2.9912e-02,  2.5977e-01],\n","        [-5.6451e-02, -2.3261e-02, -9.2477e-03,  6.2519e-03,  5.4375e-02],\n","        [-1.3063e-01, -5.3879e-02, -2.1443e-02,  1.4456e-02,  1.2560e-01],\n","        [-3.1939e-01, -1.3167e-01, -5.2370e-02,  3.5358e-02,  3.0739e-01],\n","        [-2.1728e-01, -8.9633e-02, -3.5671e-02,  2.4055e-02,  2.0898e-01],\n","        [-4.8621e-01, -2.0045e-01, -7.9762e-02,  5.3858e-02,  4.6793e-01],\n","        [-4.3935e-01, -1.8119e-01, -7.2074e-02,  4.8632e-02,  4.2237e-01],\n","        [-2.7609e-01, -1.1392e-01, -4.5321e-02,  3.0588e-02,  2.6522e-01],\n","        [-2.4961e-01, -1.0291e-01, -4.0941e-02,  2.7645e-02,  2.4017e-01],\n","        [-2.0902e-01, -8.6261e-02, -3.4360e-02,  2.3138e-02,  2.0080e-01],\n","        [-1.3989e-01, -5.7704e-02, -2.2961e-02,  1.5505e-02,  1.3447e-01],\n","        [-3.6617e-01, -1.5103e-01, -6.0062e-02,  4.0533e-02,  3.5169e-01],\n","        [-3.8501e-01, -1.5885e-01, -6.3236e-02,  4.2603e-02,  3.6987e-01],\n","        [-1.8682e-01, -7.7090e-02, -3.0681e-02,  2.0673e-02,  1.7945e-01],\n","        [-3.1668e-01, -1.3058e-01, -5.1951e-02,  3.5058e-02,  3.0453e-01],\n","        [-1.6699e-01, -6.8880e-02, -2.7416e-02,  1.8487e-02,  1.6049e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward>)\n","torch.Size([32, 5])\n","cluster_var:\n","tensor([2, 0, 2, 4, 2, 2, 0, 1, 0, 0, 4, 0, 4, 2, 4, 3, 2, 0, 2, 1, 4, 4, 1, 4,\n","        2, 3, 4, 0, 0, 0, 4, 1], device='cuda:0')\n","torch.Size([32])\n","Progress report:\tEpoch: [5][400/1127]\tTime: 0.347 (avg: 0.385)\tData: 0.000 (avg: 0.031)\tLoss: 1.6095 (avg: 1.6061)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jOsHcVHBWPf8","colab_type":"text"},"source":["## Test"]},{"cell_type":"code","metadata":{"id":"Aw7S0TmcWPC7","colab_type":"code","colab":{}},"source":["if mode == 'test':\n","    test_check = os.path.join(mydrive, test_path)\n","    print(test_check)\n","    assert os.path.isdir(test_check) is True, 'No test set detected.'\n","\n","    print('Testing')\n","    model.eval()\n","    test_dataset = datasets.ImageFolder(os.path.join(mydrive,test_path),\n","                                        transform=tra)\n","    test_loader = torch.utils.data.DataLoader(\n","        test_dataset,\n","        batch_size=1,\n","        shuffle=False,\n","        num_workers=24, \n","        pin_memory=True,\n","    )\n","    print(len(test_dataset))\n","    print(len(test_loader))\n","\n","   \n","    hit = 0\n","\n","    for i, (input_tensor, ground_truth) in enumerate(test_loader):\n","        with torch.no_grad():\n","            predict = model(input_).data.cpu().numpy()\n","        # remove batch\n","        predict = np.squeeze(predict)\n","        result = np.where(predict == np.amax(predict))\n","\n","        ground_truth =  np.squeeze(ground_truth)\n","        result =  np.squeeze(result)\n","        print('predict', predict)\n","        print('predict', result)\n","        print('ground_truth', ground_truth)\n","        if predict == ground_truth:\n","            hit = hit + 1\n","            print('hit')\n","        else:\n","            print('miss')\n","    print(\"acc:\", hit/len(test_loader) )\n"],"execution_count":null,"outputs":[]}]}